# Spec 010.1: Health Dashboard (F007 Phase 1)

**Status:** Draft
**Depends on:** Existing event log, Heart, Brain tables
**Phase:** 1 of 4 (F007 Metrics & Growth implementation)

## Problem

We have no visibility into system health without manually querying Postgres. The 009.1 spec review revealed this gap â€” three reviewers had to run raw SQL to discover that:

- Episode close rate is 85% (not 27% as initially assumed)
- Fact dedup already works (0 duplicates)
- Censor escalation already works (built into censors.py)
- All proposed schema changes already existed

A health dashboard would have shown this in seconds.

### What Exists Today

**Data sources (already collecting):**

| Source | Table | Records | What It Tells Us |
|--------|-------|---------|-----------------|
| Event log | `nous_system.events` | 289 turns, 86 episodes, 85 decisions, 64 facts | Throughput, event distribution |
| Episodes | `heart.episodes` | 86 total (22 success, 51 abandoned, 13 null) | Completion rate, outcomes |
| Facts | `heart.facts` | 53 active | Memory volume, dedup rate |
| Decisions | `brain.decisions` | 85 total, 85 reviewed | Decision quality, accuracy |
| Calibration | `brain.calibration_snapshots` | 0 | (empty â€” needs investigation) |
| Procedures | `heart.procedures` | ~3 | Skill inventory |
| Censors | `heart.censors` | 3 (0 activations) | Guardrail health |
| Working Memory | `heart.working_memory` | Per-session | Current context |
| Usage Tracker | In-memory (UsageTracker) | Per-session | Context relevance (not persisted) |

**What's NOT collected:**
- Per-turn context metrics (tokens loaded, referenced, latency) â€” Phase 2
- User satisfaction signals â€” Phase 4
- Mistake repetition analysis â€” Phase 4

### Goal

Single REST endpoint that computes health metrics from existing tables. Zero new data collection. Zero new event handlers. Pure read-only aggregation.

---

## Architecture

### Simple Design

```
GET /health
  â”‚
  â”œâ”€â”€ HealthService.compute()
  â”‚     â”œâ”€â”€ _episode_health()     â€” completion rate, outcomes, age distribution
  â”‚     â”œâ”€â”€ _fact_health()        â€” active/superseded/inactive counts, dedup rate
  â”‚     â”œâ”€â”€ _decision_health()    â€” total, reviewed, accuracy, confidence stats
  â”‚     â”œâ”€â”€ _censor_health()      â€” activation counts, escalation status
  â”‚     â”œâ”€â”€ _procedure_health()   â€” effectiveness, activation counts
  â”‚     â”œâ”€â”€ _event_throughput()   â€” turns/day, facts/day, decisions/day
  â”‚     â””â”€â”€ _memory_volume()      â€” total records by type
  â”‚
  â””â”€â”€ Returns HealthReport (JSON)
```

### Module Structure

```
nous/
  â”œâ”€â”€ api/
  â”‚   â””â”€â”€ rest.py          â€” add GET /health endpoint
  â””â”€â”€ metrics/
      â”œâ”€â”€ __init__.py
      â””â”€â”€ health.py        â€” HealthService
```

---

## Component Details

### HealthService

```python
class HealthService:
    """Computes system health metrics from existing tables.
    
    No new data collection â€” pure aggregation of what's already stored.
    All queries are read-only.
    """
    
    def __init__(self, session_factory):
        self._session_factory = session_factory
    
    async def compute(self, agent_id: str | None = None) -> HealthReport:
        """Compute full health report."""
        async with self._session_factory() as session:
            return HealthReport(
                timestamp=datetime.utcnow(),
                episodes=await self._episode_health(session, agent_id),
                facts=await self._fact_health(session, agent_id),
                decisions=await self._decision_health(session, agent_id),
                censors=await self._censor_health(session, agent_id),
                procedures=await self._procedure_health(session, agent_id),
                throughput=await self._event_throughput(session, agent_id),
                volume=await self._memory_volume(session, agent_id),
            )
```

### Episode Health

```python
async def _episode_health(self, session: AsyncSession, agent_id: str | None) -> EpisodeHealth:
    """Episode lifecycle metrics."""
    
    # Outcome distribution
    rows = await session.execute(text("""
        SELECT 
            COUNT(*) as total,
            COUNT(ended_at) as closed,
            COUNT(*) FILTER (WHERE outcome = 'success') as success,
            COUNT(*) FILTER (WHERE outcome = 'abandoned') as abandoned,
            COUNT(*) FILTER (WHERE outcome IS NULL AND ended_at IS NOT NULL) as closed_no_outcome,
            COUNT(*) FILTER (WHERE ended_at IS NULL) as still_open,
            COUNT(*) FILTER (WHERE summary IS NOT NULL) as has_summary,
            AVG(EXTRACT(EPOCH FROM (ended_at - started_at))) FILTER (WHERE ended_at IS NOT NULL) as avg_duration_secs
        FROM heart.episodes
        WHERE (:agent_id IS NULL OR agent_id = :agent_id)
    """), {"agent_id": agent_id})
    
    r = rows.mappings().one()
    total = r["total"] or 0
    closed = r["closed"] or 0
    
    return EpisodeHealth(
        total=total,
        closed=closed,
        still_open=r["still_open"] or 0,
        success=r["success"] or 0,
        abandoned=r["abandoned"] or 0,
        close_rate=round(closed / total, 3) if total > 0 else None,
        summary_rate=round((r["has_summary"] or 0) / total, 3) if total > 0 else None,
        avg_duration_minutes=round((r["avg_duration_secs"] or 0) / 60, 1),
    )
```

### Fact Health

```python
async def _fact_health(self, session: AsyncSession, agent_id: str | None) -> FactHealth:
    """Fact memory metrics."""
    
    rows = await session.execute(text("""
        SELECT
            COUNT(*) as total,
            COUNT(*) FILTER (WHERE active = true AND superseded_by IS NULL) as active,
            COUNT(*) FILTER (WHERE active = false) as inactive,
            COUNT(*) FILTER (WHERE superseded_by IS NOT NULL) as superseded,
            COUNT(*) FILTER (WHERE confirmation_count > 0) as confirmed,
            COUNT(*) FILTER (WHERE confirmation_count >= 3) as core,
            AVG(confirmation_count) as avg_confirmations,
            COUNT(DISTINCT subject) as unique_subjects
        FROM heart.facts
        WHERE (:agent_id IS NULL OR agent_id = :agent_id)
    """), {"agent_id": agent_id})
    
    r = rows.mappings().one()
    total = r["total"] or 0
    active = r["active"] or 0
    
    return FactHealth(
        total=total,
        active=active,
        inactive=r["inactive"] or 0,
        superseded=r["superseded"] or 0,
        confirmed=r["confirmed"] or 0,
        core=r["core"] or 0,
        accuracy=round(active / total, 3) if total > 0 else None,
        avg_confirmations=round(r["avg_confirmations"] or 0, 2),
        unique_subjects=r["unique_subjects"] or 0,
    )
```

### Decision Health

```python
async def _decision_health(self, session: AsyncSession, agent_id: str | None) -> DecisionHealth:
    """Decision quality metrics from Brain."""
    
    rows = await session.execute(text("""
        SELECT
            COUNT(*) as total,
            COUNT(outcome) as reviewed,
            COUNT(*) FILTER (WHERE outcome = 'success') as successful,
            COUNT(*) FILTER (WHERE outcome = 'failure') as failed,
            COUNT(*) FILTER (WHERE outcome = 'partial') as partial,
            AVG(confidence) as avg_confidence,
            STDDEV(confidence) as confidence_stddev,
            MIN(confidence) as min_confidence,
            MAX(confidence) as max_confidence
        FROM brain.decisions
        WHERE (:agent_id IS NULL OR agent_id = :agent_id)
    """), {"agent_id": agent_id})
    
    r = rows.mappings().one()
    reviewed = r["reviewed"] or 0
    successful = r["successful"] or 0
    
    # Brier score: avg (confidence - outcome)^2 where outcome is 1 for success, 0 for failure
    brier_rows = await session.execute(text("""
        SELECT AVG(
            POWER(confidence - CASE WHEN outcome = 'success' THEN 1.0 ELSE 0.0 END, 2)
        ) as brier_score
        FROM brain.decisions
        WHERE outcome IS NOT NULL
        AND outcome IN ('success', 'failure')
        AND (:agent_id IS NULL OR agent_id = :agent_id)
    """), {"agent_id": agent_id})
    
    brier = brier_rows.scalar()
    
    return DecisionHealth(
        total=r["total"] or 0,
        reviewed=reviewed,
        successful=successful,
        failed=r["failed"] or 0,
        partial=r["partial"] or 0,
        accuracy=round(successful / reviewed, 3) if reviewed > 0 else None,
        brier_score=round(brier, 4) if brier is not None else None,
        avg_confidence=round(r["avg_confidence"] or 0, 3),
        confidence_stddev=round(r["confidence_stddev"] or 0, 3),
        review_rate=round(reviewed / (r["total"] or 1), 3),
    )
```

### Censor Health

```python
async def _censor_health(self, session: AsyncSession, agent_id: str | None) -> CensorHealth:
    """Censor/guardrail metrics."""
    
    rows = await session.execute(text("""
        SELECT
            COUNT(*) as total,
            COUNT(*) FILTER (WHERE active = true) as active_count,
            SUM(activation_count) as total_activations,
            COUNT(*) FILTER (WHERE action = 'warn') as warn_count,
            COUNT(*) FILTER (WHERE action = 'block') as block_count,
            COUNT(*) FILTER (WHERE action = 'absolute') as absolute_count
        FROM heart.censors
        WHERE (:agent_id IS NULL OR agent_id = :agent_id)
    """), {"agent_id": agent_id})
    
    r = rows.mappings().one()
    
    return CensorHealth(
        total=r["total"] or 0,
        active=r["active_count"] or 0,
        total_activations=r["total_activations"] or 0,
        warn=r["warn_count"] or 0,
        block=r["block_count"] or 0,
        absolute=r["absolute_count"] or 0,
    )
```

### Procedure Health

```python
async def _procedure_health(self, session: AsyncSession, agent_id: str | None) -> ProcedureHealth:
    """Procedure/skill metrics."""
    
    rows = await session.execute(text("""
        SELECT
            COUNT(*) as total,
            COUNT(*) FILTER (WHERE active = true) as active_count,
            SUM(activation_count) as total_activations,
            SUM(success_count) as total_successes,
            AVG(CASE WHEN activation_count > 0 
                THEN success_count::float / activation_count 
                ELSE NULL END) as avg_effectiveness
        FROM heart.procedures
        WHERE (:agent_id IS NULL OR agent_id = :agent_id)
    """), {"agent_id": agent_id})
    
    r = rows.mappings().one()
    
    return ProcedureHealth(
        total=r["total"] or 0,
        active=r["active_count"] or 0,
        total_activations=r["total_activations"] or 0,
        total_successes=r["total_successes"] or 0,
        avg_effectiveness=round(r["avg_effectiveness"] or 0, 3),
    )
```

### Event Throughput

```python
async def _event_throughput(self, session: AsyncSession, agent_id: str | None) -> EventThroughput:
    """Event rates over recent periods."""
    
    # Last 24 hours
    rows = await session.execute(text("""
        SELECT
            event_type,
            COUNT(*) as count_24h
        FROM nous_system.events
        WHERE created_at > NOW() - INTERVAL '24 hours'
        AND (:agent_id IS NULL OR agent_id = :agent_id)
        GROUP BY event_type
        ORDER BY count_24h DESC
    """), {"agent_id": agent_id})
    
    daily = {r["event_type"]: r["count_24h"] for r in rows.mappings()}
    
    # Last 7 days (for weekly averages)
    rows7 = await session.execute(text("""
        SELECT
            event_type,
            COUNT(*) as count_7d
        FROM nous_system.events
        WHERE created_at > NOW() - INTERVAL '7 days'
        AND (:agent_id IS NULL OR agent_id = :agent_id)
        GROUP BY event_type
    """), {"agent_id": agent_id})
    
    weekly = {r["event_type"]: r["count_7d"] for r in rows7.mappings()}
    
    return EventThroughput(
        turns_24h=daily.get("turn_completed", 0),
        facts_24h=daily.get("fact_learned", 0),
        decisions_24h=daily.get("decision_recorded", 0),
        episodes_24h=daily.get("episode_started", 0),
        turns_7d_avg=round(weekly.get("turn_completed", 0) / 7, 1),
        facts_7d_avg=round(weekly.get("fact_learned", 0) / 7, 1),
        decisions_7d_avg=round(weekly.get("decision_recorded", 0) / 7, 1),
    )
```

### Memory Volume

```python
async def _memory_volume(self, session: AsyncSession, agent_id: str | None) -> MemoryVolume:
    """Total record counts by type."""
    
    counts = {}
    for table, schema in [
        ("facts", "heart"), ("episodes", "heart"),
        ("procedures", "heart"), ("censors", "heart"),
        ("decisions", "brain"), ("working_memory", "heart"),
    ]:
        row = await session.execute(
            text(f"SELECT COUNT(*) FROM {schema}.{table} WHERE (:aid IS NULL OR agent_id = :aid)"),
            {"aid": agent_id},
        )
        counts[table] = row.scalar() or 0
    
    return MemoryVolume(**counts)
```

---

## Data Models

```python
from dataclasses import dataclass
from datetime import datetime


@dataclass
class EpisodeHealth:
    total: int
    closed: int
    still_open: int
    success: int
    abandoned: int
    close_rate: float | None
    summary_rate: float | None
    avg_duration_minutes: float

@dataclass
class FactHealth:
    total: int
    active: int
    inactive: int
    superseded: int
    confirmed: int
    core: int
    accuracy: float | None
    avg_confirmations: float
    unique_subjects: int

@dataclass
class DecisionHealth:
    total: int
    reviewed: int
    successful: int
    failed: int
    partial: int
    accuracy: float | None
    brier_score: float | None
    avg_confidence: float
    confidence_stddev: float
    review_rate: float

@dataclass
class CensorHealth:
    total: int
    active: int
    total_activations: int
    warn: int
    block: int
    absolute: int

@dataclass
class ProcedureHealth:
    total: int
    active: int
    total_activations: int
    total_successes: int
    avg_effectiveness: float

@dataclass
class EventThroughput:
    turns_24h: int
    facts_24h: int
    decisions_24h: int
    episodes_24h: int
    turns_7d_avg: float
    facts_7d_avg: float
    decisions_7d_avg: float

@dataclass
class MemoryVolume:
    facts: int
    episodes: int
    procedures: int
    censors: int
    decisions: int
    working_memory: int

@dataclass
class HealthReport:
    timestamp: datetime
    episodes: EpisodeHealth
    facts: FactHealth
    decisions: DecisionHealth
    censors: CensorHealth
    procedures: ProcedureHealth
    throughput: EventThroughput
    volume: MemoryVolume
```

---

## REST Endpoint

```python
@app.get("/health")
async def get_health(agent_id: str | None = None):
    """System health dashboard.
    
    Returns computed metrics from existing tables.
    No new data collection â€” pure aggregation.
    
    Optional: ?agent_id=nous-default to filter by agent.
    """
    report = await health_service.compute(agent_id)
    return dataclasses.asdict(report)
```

### Example Response

```json
{
  "timestamp": "2026-02-27T23:30:00Z",
  "episodes": {
    "total": 86,
    "closed": 73,
    "still_open": 0,
    "success": 22,
    "abandoned": 51,
    "close_rate": 0.849,
    "summary_rate": 0.802,
    "avg_duration_minutes": 32.5
  },
  "facts": {
    "total": 56,
    "active": 53,
    "inactive": 3,
    "superseded": 0,
    "confirmed": 3,
    "core": 0,
    "accuracy": 0.946,
    "avg_confirmations": 0.05,
    "unique_subjects": 28
  },
  "decisions": {
    "total": 85,
    "reviewed": 85,
    "successful": 72,
    "failed": 8,
    "partial": 5,
    "accuracy": 0.847,
    "brier_score": 0.042,
    "avg_confidence": 0.78,
    "confidence_stddev": 0.12,
    "review_rate": 1.0
  },
  "censors": {
    "total": 3,
    "active": 3,
    "total_activations": 0,
    "warn": 1,
    "block": 2,
    "absolute": 0
  },
  "procedures": {
    "total": 3,
    "active": 3,
    "total_activations": 0,
    "total_successes": 0,
    "avg_effectiveness": 0.0
  },
  "throughput": {
    "turns_24h": 42,
    "facts_24h": 5,
    "decisions_24h": 8,
    "episodes_24h": 6,
    "turns_7d_avg": 41.3,
    "facts_7d_avg": 9.1,
    "decisions_7d_avg": 12.1
  },
  "volume": {
    "facts": 56,
    "episodes": 86,
    "procedures": 3,
    "censors": 3,
    "decisions": 85,
    "working_memory": 4
  }
}
```

---

## Integration

### Registration in main.py

```python
from nous.metrics.health import HealthService

# After session_factory is created
health_service = HealthService(session_factory)

# In REST app setup
app.state.health_service = health_service
```

### Agent-Callable Tool (Optional)

```python
# In tools.py â€” let Nous check its own health
async def check_health() -> str:
    """Check system health metrics."""
    report = await health_service.compute(agent_id="nous-default")
    return _format_health_report(report)

def _format_health_report(r: HealthReport) -> str:
    lines = ["ðŸ“Š System Health Report\n"]
    
    ep = r.episodes
    lines.append(f"ðŸŽ¬ Episodes: {ep.total} total, {ep.close_rate:.0%} close rate, {ep.success} success")
    
    f = r.facts
    lines.append(f"ðŸ§  Facts: {f.active} active, {f.confirmed} confirmed, {f.accuracy:.0%} accuracy")
    
    d = r.decisions
    lines.append(f"ðŸŽ¯ Decisions: {d.total} total, {d.accuracy:.0%} accuracy, Brier {d.brier_score:.3f}")
    
    c = r.censors
    lines.append(f"ðŸ›¡ Censors: {c.active} active, {c.total_activations} total activations")
    
    p = r.procedures
    lines.append(f"ðŸ”§ Procedures: {p.active} active, {p.total_activations} activations")
    
    t = r.throughput
    lines.append(f"\nðŸ“ˆ Last 24h: {t.turns_24h} turns, {t.facts_24h} facts, {t.decisions_24h} decisions")
    lines.append(f"ðŸ“Š 7-day avg: {t.turns_7d_avg}/day turns, {t.facts_7d_avg}/day facts")
    
    return "\n".join(lines)
```

---

## Schema Changes

**None.** This phase is pure read-only aggregation. No new tables, no migrations, no ALTER statements.

---

## Testing Strategy

### Unit tests

- `test_health_service.py`
  - Each `_*_health()` method returns correct dataclass with expected fields
  - Empty tables â†’ zero counts, None rates (no division by zero)
  - agent_id filter works (returns only that agent's data)
  - Brier score computation matches manual calculation

### Integration tests

- `GET /health` returns 200 with valid JSON
- Response matches HealthReport schema
- Metrics update after inserting test data (fact, episode, decision)

### Edge cases

- No episodes â†’ close_rate is None, not 0/0
- No reviewed decisions â†’ accuracy is None
- No events in last 24h â†’ throughput counts are 0
- Mixed agent_ids â†’ filter returns correct subset

---

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Slow queries on large tables | Low | All queries use COUNT/AVG aggregates. At current scale (<300 events, <100 episodes), each query is <10ms. Add indexes if needed at 10K+. |
| Stale data if read replica used | Low | We query primary directly. Metrics are point-in-time, staleness is acceptable. |
| Missing agent_id on some records | Low | WHERE clause uses IS NULL fallback. Check actual data for NULL agent_ids. |
| Episode outcome column values vary | Low | Query uses exact string match. Verify actual values in DB match expected ('success', 'abandoned', 'failure'). |

---

## Success Criteria

- `GET /health` returns complete health report in < 500ms
- All metrics computable from existing tables (no new data collection)
- Nous can call `check_health()` tool to inspect its own state
- Dashboard would have caught 009.1's redundancy issues (shows existing dedup rate, censor activation count, episode close rate)
- No schema migrations required

---

## What This Enables

With Phase 1 in place:
- **Phase 2 (Context Metrics):** Adds per-turn instrumentation â†’ feeds into the same HealthReport
- **Phase 3 (Growth Reports):** Weekly aggregation â†’ compares HealthReports over time â†’ LLM analysis
- **Phase 4 (Satisfaction + Mistake Repetition):** Adds Level 4 metrics â†’ the "is Nous getting smarter?" question

Phase 1 also enables:
- **Spec reviews grounded in data** â€” no more writing specs for problems that don't exist
- **Nous self-awareness** â€” agent can check its own health and report anomalies
- **Baseline establishment** â€” first report becomes the comparison point for all future improvements
