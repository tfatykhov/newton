# 005.1 Smart Context Preparation — Implementation Plan

**Spec:** [005.1-smart-context-preparation.md](005.1-smart-context-preparation.md)
**Review Team:** nous-ctx-arch-005.1, nous-ctx-spec-005.1, nous-ctx-devil-005.1
**Decision IDs:** Team `8cb8fe79`, Arch `82d5a98a`, Spec `cad2dd5c`, Devil `934cc562`, Synthesis `e40aef17`
**Date:** 2026-02-23

## Review Summary

Three-agent review produced **41 raw findings** (after dedup: **7 P0, 9 P1, 11 P2**). Key insight from all reviewers: **the 3 standalone files (intent.py, usage_tracker.py, dedup.py) are clean and self-consistent. ALL issues are at integration seams** where new code meets existing code.

### Convergence Matrix

| Finding | Arch | Spec | Devil | Consensus |
|---------|------|------|-------|-----------|
| recalled_*_ids never populated | P0-1 | (implicit) | P1-5 | **3/3 — P0** |
| embed per-item not batch | P1-2 | P0-1 | (implicit) | **2/3 — P0** |
| Constructor gaps (3 components) | P1-1 | — | P0-2 | **2/3 — P0** |
| conversation_messages not plumbed | P0-4 | — | P1-8 | **2/3 — P0** |
| FrameEngine.select() missing agent_id | — | — | P0-1 | **Confirmed by lead — P0** |
| budget_overrides semantics undefined | P0-2 | — | P2-15 | **2/3 — P0** |
| recency_weight dead field | P0-3 | — | P1-10 | **2/3 — P0** |
| _get_section_content phantom method | P1-3 | — | P0-3 | **2/3 — P1** |
| TurnContext lacks sections/IDs | — | — | P0-4 | **Tied to recalled_*_ids — P0** |
| Jaccard wrong metric | — | P1-1 | — | **Unique, verified — P1** |
| apply_frame_boost silently lost | — | — | P1-7 | **Unique, verified — P1** |
| UsageTracker unbounded O(n) | P1-4 | P0-2 | — | **2/3 — P1** |
| No embedding error handling | — | P1-3 | — | **Unique, verified — P1** |

---

## Consolidated Issues

### P0 — BLOCKERS (7)

**F1: Feedback loop data flow broken (3/3 convergence)**
- `context.py:build()` returns `(str, list[ContextSection])` but never extracts memory IDs from Brain.query() / Heart.search_*() results
- `layer.py:109-110` initializes `recalled_decision_ids=[]`, `recalled_fact_ids=[]` — never filled
- `TurnContext` has the fields but they're always empty
- Spec's post_turn usage tracking (lines 553-565) iterates empty lists — entire feedback loop is dead
- **Fix:** Introduce `BuildResult` dataclass returned by `build()` containing system_prompt, sections, and `recalled_ids: dict[str, list[str]]` mapping memory_type to list of IDs. Populate from query results. Layer.py extracts into TurnContext.

**F2: Dedup uses embed() per-item — O(n*m) API calls (2/3)**
- `dedup.py:451-456` calls `embed(msg)` individually per conversation message and per memory
- With C=5, M=20: 25 sequential HTTP calls to OpenAI (~100ms each = 2.5s latency)
- `EmbeddingProvider.embed_batch()` exists at `embeddings.py:46-58`
- **Fix:** Batch all texts into single `embed_batch()` call. 25 API calls → 1.

**F3: IntentClassifier, UsageTracker, ConversationDeduplicator never instantiated (2/3)**
- Spec references `self._intent_classifier` and `self._usage_tracker` in layer.py but shows no constructor changes
- `ConversationDeduplicator` used in context.py build() but never created
- **Fix:** Add to `CognitiveLayer.__init__()`:
  - `self._intent_classifier = IntentClassifier()`
  - `self._usage_tracker = UsageTracker()`
- Add to `ContextEngine.__init__()`:
  - `deduplicator: ConversationDeduplicator | None = None` parameter
  - Created by CognitiveLayer using `self._brain.embeddings` (public attr at `brain.py:63`)

**F4: conversation_messages never plumbed from runner.py (2/3)**
- `runner.py:132` calls `pre_turn(agent_id, session_id, user_message)` — no conversation_messages
- `Conversation.messages` at `runner.py:47` holds the data but it's never extracted
- Dedup feature (D4) is dead code at runtime
- **Fix:** Add to runner.py `run_turn()`:
  ```python
  recent_messages = [m.content for m in conversation.messages[-8:] if m.role == "user"]
  ctx = await self._cognitive.pre_turn(
      agent_id, session_id, user_message,
      session=session, conversation_messages=recent_messages
  )
  ```
  Window size 8 is the max (decision frame) — context.py can further trim based on ContextBudget.conversation_window.

**F5: FrameEngine.select() missing agent_id (confirmed by lead + devil)**
- Spec line 529: `self._frames.select(input_text, session=session)`
- Actual signature: `select(self, agent_id: str, input_text: str, session=None)`
- **Fix:** Spec code must use `self._frames.select(agent_id, input_text, session=session)` — matches current layer.py:102.

**F6: budget_overrides merge semantics undefined (2/3)**
- `RetrievalPlan.budget_overrides` is `dict[str, int]` but spec never says REPLACE or ADD
- Additive would exceed totals (3000+3500=6500 for decisions in 12000 budget)
- **Fix:** REPLACE semantics. Add `ContextBudget.apply_overrides(overrides: dict[str, int])` method:
  ```python
  def apply_overrides(self, overrides: dict[str, int]) -> None:
      for key, value in overrides.items():
          if hasattr(self, key):
              setattr(self, key, value)
  ```
  Called in `build()` after `ContextBudget.for_frame()`, before section assembly.

**F7: recency_weight is dead data — no consumer in Brain/Heart APIs (2/3)**
- `RetrievalQuery.recency_weight` set from temporal signals but Brain.query() and Heart search methods have no recency parameter
- Adding recency to query APIs requires SQL changes — out of scope
- **Fix:** Remove `recency_weight` from `RetrievalQuery`. Use temporal signals only for post-retrieval re-ranking: sort results by `created_at` weighted by `signals.temporal_recency`. Implement as a helper in context.py. Defer full recency support to future spec.

---

### P1 — IMPORTANT (9)

**F8: _get_section_content() phantom method (2/3)**
- Spec line 556 calls `self._get_section_content(mid, turn_context)` — method doesn't exist anywhere
- TurnContext only stores `system_prompt` (flat string), not per-memory content
- **Fix:** Add `recalled_content_map: dict[str, str]` to TurnContext (memory_id → content text). Populated during `build()` alongside recalled_ids. Used in post_turn for overlap computation.

**F9: Jaccard wrong metric for usage detection (spec-specialist unique)**
- `compute_overlap()` uses `|A∩B| / |A∪B|` — biased against long contexts
- Example: 2000-word context, 100-word response referencing all 100 words → Jaccard=0.05 (below 0.15 threshold)
- **Fix:** Use containment coefficient: `|A∩B| / min(|A|, |B|)`. Same example → 100/100=1.0.

**F10: apply_frame_boost silently lost (devil unique)**
- Current `context.py:154,173,193` applies `apply_frame_boost()` to facts, procedures, episodes
- Spec changes section doesn't mention it — implementer replacing logic wholesale would lose it
- **Fix:** Spec must explicitly preserve `apply_frame_boost` in pipeline. Order: retrieve → apply_frame_boost → dedup → usage_boost → budget_truncate.

**F11: UsageTracker._compute_decayed_score() unbounded O(n) (2/3)**
- Iterates ALL `_records` (flat list) per call. No cap, no pruning.
- After 500 turns × 20 retrievals = 10,000 records → 200,000 iterations/turn
- **Fix:** (a) Index `_records` by memory_id: `dict[str, list[UsageRecord]]`. (b) Cap at MAX_RECORDS=5000 with time-based pruning (drop >21 days = 3× half-life where decay <1%). (c) Pre-compute score incrementally.

**F12: No error handling for embedding failures in dedup (spec unique)**
- If `embed()` or `embed_batch()` throws (timeout, rate limit), exception propagates through build() → pre_turn()
- **Fix:** Wrap embedding dedup in try/except, fall back to keyword-based dedup (already implemented in else branch), log warning.

**F13: conversation_window declared but unwired (spec unique)**
- D7 defines per-frame window sizes but `RetrievalPlan` has no `conversation_window` field
- `IntentClassifier.plan_retrieval()` never sets it
- **Fix:** `conversation_window` stays on `ContextBudget` (where it already is per spec). `build()` reads it from `budget.conversation_window` to trim `conversation_messages` before passing to dedup. No need to duplicate in RetrievalPlan.

**F14: EmbeddingProvider access path unspecified (devil unique)**
- ConversationDeduplicator needs EmbeddingProvider but spec doesn't say where it comes from
- Brain has `self.embeddings` (public), Heart has `self._embeddings` (private)
- **Fix:** CognitiveLayer passes `self._brain.embeddings` to ContextEngine, which passes to ConversationDeduplicator. Document in constructor chain.

**F15: pre_turn parameter name inconsistency (2/3)**
- Spec uses `input_text`, actual uses `user_input`
- **Fix:** Keep `user_input` (no rename). Avoid breaking existing callers and tests.

**F16: post_turn spec signature mismatch (devil unique)**
- Spec shows `post_turn(self, turn_context, turn_result)` — drops agent_id, session_id, swaps order
- **Fix:** This is partial code showing additions only. Implementation must preserve actual signature `post_turn(self, agent_id, session_id, turn_result, turn_context, session=None)`.

---

### P2 — NICE-TO-HAVE (11)

| ID | Finding | Fix |
|----|---------|-----|
| F17 | Greeting patterns incomplete (no "good afternoon", "howdy") | Extend `_GREETING_PATTERNS` regex |
| F18 | Question-starter regex missing "did/will/would/could/has/have" | Extend regex, mitigated by `?` check |
| F19 | ALL-CAPS acronyms dropped from topic_keywords ("AI", "ML") | Add `r"\b[A-Z]{2,}\b"` branch |
| F20 | Short non-greeting input wastes queries ("ok", "yes") | Add short-circuit for <3 word non-question non-greeting |
| F21 | Dedup thresholds (0.85 embedding, 0.5 keyword) undocumented | Add calibration rationale in code comments |
| F22 | Lazy import in dedup fallback fragile | Move `UsageTracker` import to module level or inline Jaccard |
| F23 | boost_factor range [0.5, 1.5] rationale undocumented | Add docstring explaining cold-start tradeoff |
| F24 | ContextBudget.for_frame() ellipsis hides values | Show full field sets in spec, or explicitly say "add field" |
| F25 | __init__.py exports not updated | Add new classes to `nous/cognitive/__init__.py` |
| F26 | skip_types vs budget_overrides interaction ambiguous | Clarify: skip_types is primary (skips query), budget=0 is secondary |
| F27 | query_text falls back to empty string | Fall back to original `user_input` instead |

---

## Strategy: BUILD STANDALONE → WIRE INTEGRATION

All issues are at integration seams. The standalone files are clean. Strategy:
1. Build the 3 new files first with all P0/P1 fixes baked in
2. Modify schemas.py (add fields, BuildResult)
3. Modify context.py (accept new components, return BuildResult, wire dedup + usage)
4. Modify layer.py (instantiate components, pass through pre_turn/post_turn)
5. Modify runner.py (plumb conversation_messages)
6. Tests

---

## Implementation Phases

### Phase A: New Standalone Files (~180 lines)

Create the 3 new files with all fixes applied:

**`nous/cognitive/intent.py`** (~120 lines)
- IntentSignals, RetrievalQuery (WITHOUT recency_weight — F7), RetrievalPlan
- IntentClassifier with classify() and plan_retrieval()
- Fixes: F5 (agent_id not relevant here), F17-F20 (extended patterns), F19 (ALL-CAPS), F27 (fallback to input_text)

**`nous/cognitive/usage_tracker.py`** (~110 lines)
- UsageRecord, MemoryUsageStats, UsageTracker
- Fixes: F9 (containment coefficient instead of Jaccard), F11 (indexed records by memory_id, MAX_RECORDS=5000, time-based pruning)

**`nous/cognitive/dedup.py`** (~80 lines)
- DeduplicationResult, ConversationDeduplicator
- Fixes: F2 (use embed_batch), F12 (try/except with keyword fallback), F22 (module-level import)

### Phase B: Schema + Context Engine Changes (~80 lines)

**`nous/cognitive/schemas.py`** changes:
- Add `conversation_window: int = 5` to ContextBudget + per-frame values (F13)
- Add `recalled_procedure_ids`, `recalled_episode_ids` to TurnContext
- Add `recalled_content_map: dict[str, str]` to TurnContext (F8)
- Add `ContextBudget.apply_overrides()` method (F6)
- New `BuildResult` dataclass: system_prompt, sections, recalled_ids dict (F1)

**`nous/cognitive/context.py`** changes:
- Accept `ConversationDeduplicator | None` in __init__ (F3, F14)
- Update `build()` signature: add conversation_messages, retrieval_plan, usage_tracker params (all optional)
- Collect memory IDs from query results into recalled_ids dict (F1)
- Apply budget_overrides via `budget.apply_overrides(plan.budget_overrides)` (F6)
- Skip types in `plan.skip_types` (F26: primary skip mechanism)
- After retrieval: apply_frame_boost THEN dedup THEN usage_boost (F10 — preserve existing pipeline)
- Trim conversation_messages to `budget.conversation_window` before dedup (F13)
- Return `BuildResult` instead of tuple (F1)

### Phase C: Layer + Runner Wiring (~50 lines)

**`nous/cognitive/layer.py`** changes:
- Import IntentClassifier, UsageTracker, ConversationDeduplicator
- Add to `__init__()`: instantiate all 3 components (F3)
  - `self._intent_classifier = IntentClassifier()`
  - `self._usage_tracker = UsageTracker()`
  - Pass `ConversationDeduplicator(embedding_provider=brain.embeddings)` to ContextEngine (F14)
- Update `pre_turn()`: add `conversation_messages` param (keep `user_input` name — F15)
  - Classify intent: `signals = self._intent_classifier.classify(user_input, frame)`
  - Plan retrieval: `plan = self._intent_classifier.plan_retrieval(signals)`
  - Pass plan + usage_tracker + conversation_messages to `build()`
  - Extract recalled_ids from BuildResult into TurnContext (F1)
- Update `post_turn()`: add usage tracking after assessment (F8, F16 — preserve actual signature)
  - For each recalled memory: compute containment overlap, record via usage_tracker

**`nous/api/runner.py`** changes:
- Extract recent conversation messages before `pre_turn()` call (F4)
- Pass `conversation_messages` to `pre_turn()`

**`nous/cognitive/__init__.py`** changes:
- Export new classes (F25)

### Phase D: Tests (~260 lines)

- `tests/test_intent.py` (~80 lines): 8 tests per spec
- `tests/test_usage_tracker.py` (~60 lines): 6 tests per spec, updated for containment coefficient
- `tests/test_dedup.py` (~50 lines): 4 tests per spec, test batch embedding + error fallback
- `tests/test_context_smart.py` (~70 lines): 4 tests per spec, verify full pipeline integration

---

## Acceptance Criteria

1. `IntentClassifier.classify()` correctly identifies greetings, questions, temporal signals, memory hints
2. `IntentClassifier.plan_retrieval()` returns minimal plan for greetings, biased plan for memory hints
3. `UsageTracker` decay gives 0.5 at 7 days (verify math)
4. `UsageTracker.compute_overlap()` uses containment coefficient (NOT Jaccard)
5. `UsageTracker._records` indexed by memory_id, capped at 5000
6. `ConversationDeduplicator.check()` uses `embed_batch()` (NOT per-item embed)
7. `ConversationDeduplicator.check()` falls back to keyword overlap on embedding failure
8. `ContextEngine.build()` returns `BuildResult` with recalled IDs populated
9. `ContextEngine.build()` applies budget_overrides with REPLACE semantics
10. `ContextEngine.build()` preserves `apply_frame_boost` in pipeline
11. `CognitiveLayer.pre_turn()` accepts and passes `conversation_messages`
12. `CognitiveLayer.post_turn()` records usage for recalled memories
13. `runner.py` extracts and passes conversation_messages to pre_turn
14. All existing tests pass unchanged (backward compatibility)
15. All new tests pass
16. `pytest tests/ -v` — 0 failures

---

## Risk Assessment

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|------------|
| Embedding API latency added to critical path | Medium | High | Batch calls (F2), error fallback (F12) |
| UsageTracker memory growth | Low | Medium | Index + cap at 5000 (F11) |
| Backward compat break | Low | High | All params optional with defaults, existing tests as regression suite |
| Dedup too aggressive (filters useful context) | Low | Medium | Conservative 0.85 threshold, easy to tune |
| Intent patterns too crude | Medium | Low | Graceful degradation: unrecognized → default uniform retrieval |

---

## Team Review Performance

### nous-ctx-arch-005.1 (Architecture)
- **Findings:** 4 P0, 5 P1, 4 P2
- **Unique high-value:** P0-3 (recency_weight dead field) — only reviewer to trace through Brain/Heart API signatures
- **Overlap:** Strong on data flow gaps, correctly identified all plumbing issues
- **Quality:** Excellent — clear fix recommendations, specific line references

### nous-ctx-spec-005.1 (Algorithms)
- **Findings:** 2 P0, 3 P1, 7 P2
- **Unique high-value:** P1-1 (Jaccard→containment coefficient) — concrete mathematical proof with worked example. Only reviewer to catch this.
- **Overlap:** P0-1 (embed batch) was highest-impact find with clear 25x improvement
- **Quality:** Excellent — deep algorithmic analysis, verified decay math, concrete examples

### nous-ctx-devil-005.1 (Devil's Advocate)
- **Findings:** 4 P0, 7 P1, 4 P2
- **Unique high-value:** P1-7 (apply_frame_boost silently lost) — only reviewer to check what spec DOESN'T mention. P1-9 (ConversationDeduplicator never instantiated) — traced full constructor chain.
- **Overlap:** Confirmed all lead suspicions. Highest total issue count (15).
- **Quality:** Excellent — systematic methodology, exact line references in both spec and source

### Cross-Reviewer Convergence
- **3/3 convergence:** recalled_*_ids gap (highest confidence finding)
- **2/3 convergence:** 6 additional issues
- **Unique findings verified:** 4 (Jaccard metric, apply_frame_boost, ConversationDeduplicator instantiation, conversation_window unwired)
- **False positives:** 0 — all findings confirmed against source code
- **Lead overrides:** 2 (post_turn signature mismatch downgraded P1→P2; recency_weight deferred not removed from whole spec)
