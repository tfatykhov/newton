# Spec 009.2: Maintenance Engine (Startup Catch-up + Periodic)

**Status:** Draft
**Depends on:** 009.1 (Reactive Memory Lifecycle)
**Phase:** 2 of 4 (F008 implementation)

## Problem

After Phase 1, immediate reactions are handled (dedup, supersession, episode summarize, censor escalation). But slower transitions still need a background process:

- **Episodes age but never archive** — 90-day-old episodes retain full detail, wasting context tokens when recalled
- **Superseded facts linger** — marked superseded but never deactivated, still clutter search results if active flag isn't filtered
- **Ineffective procedures accumulate** — procedures with <40% success rate after 5+ uses should be flagged for review or retirement
- **Noisy censors stay active** — censors with >50% false positive rate should be retired
- **No catch-up if Nous was down** — if the process restarts after 3 days, overdue maintenance doesn't run

---

## Architecture

### Three-Part Design

```
1. STARTUP CATCH-UP
   Nous starts → check system.maintenance_state.last_run
   → If overdue (> maintenance_interval): run full maintenance immediately
   → Log catch-up in maintenance_history

2. PERIODIC TASK
   asyncio background task running every maintenance_interval (default: 12h)
   → Run all maintenance checks
   → Update last_run timestamp
   → Emit maintenance_completed event

3. MAINTENANCE TASKS (idempotent, safe to run anytime)
   ├── Episode archiving (30d → trim detail, 90d → summary only)
   ├── Stale fact deactivation
   ├── Procedure effectiveness review
   ├── Censor retirement
   └── Memory health snapshot
```

### Module Structure

```
nous/heart/
  ├── maintenance/
  │   ├── __init__.py
  │   ├── engine.py         — MaintenanceEngine (scheduler + catch-up)
  │   ├── episodes.py       — EpisodeArchiver
  │   ├── facts.py          — StaleFactCleaner
  │   ├── procedures.py     — ProcedureReviewer
  │   ├── censors.py        — CensorRetirer
  │   └── health.py         — MemoryHealthSnapshot
  └── ...
```

---

## Component Details

### 1. MaintenanceEngine

```python
class MaintenanceEngine:
    DEFAULT_INTERVAL_HOURS = 12
    
    def __init__(self, heart: Heart, config: MaintenanceConfig):
        self._heart = heart
        self._interval = timedelta(hours=config.interval_hours or self.DEFAULT_INTERVAL_HOURS)
        self._tasks: list[MaintenanceTask] = [
            EpisodeArchiver(heart),
            StaleFactCleaner(heart),
            ProcedureReviewer(heart),
            CensorRetirer(heart),
            MemoryHealthSnapshot(heart),
        ]
        self._background_task: asyncio.Task | None = None
    
    async def start(self, session_factory):
        """Called on Nous startup. Catch-up + schedule periodic."""
        # 1. Check if maintenance is overdue
        async with session_factory() as session:
            state = await self._get_state(session)
            if self._is_overdue(state):
                logger.info("Maintenance overdue (last_run=%s), running catch-up", state.last_run)
                await self._run_all(session, reason="catch-up")
        
        # 2. Schedule periodic task
        self._background_task = asyncio.create_task(self._periodic_loop(session_factory))
    
    async def stop(self):
        """Called on Nous shutdown."""
        if self._background_task:
            self._background_task.cancel()
    
    async def _periodic_loop(self, session_factory):
        while True:
            await asyncio.sleep(self._interval.total_seconds())
            try:
                async with session_factory() as session:
                    await self._run_all(session, reason="periodic")
            except Exception:
                logger.exception("Maintenance run failed")
    
    async def _run_all(self, session: AsyncSession, reason: str):
        """Run all maintenance tasks. Each is independent and idempotent."""
        results = {}
        for task in self._tasks:
            try:
                result = await task.run(session)
                results[task.name] = result
                logger.info("Maintenance task %s: %s", task.name, result)
            except Exception:
                logger.exception("Maintenance task %s failed", task.name)
                results[task.name] = {"error": str(e)}
        
        # Update state
        await self._update_state(session, reason=reason, results=results)
        await session.commit()
    
    def _is_overdue(self, state: MaintenanceState) -> bool:
        if state.last_run is None:
            return True
        return datetime.utcnow() - state.last_run > self._interval
```

### 2. Episode Archiver

```python
class EpisodeArchiver(MaintenanceTask):
    name = "episode_archiver"
    
    SUMMARIZE_AFTER_DAYS = 30
    ARCHIVE_AFTER_DAYS = 90
    
    async def run(self, session: AsyncSession) -> dict:
        now = datetime.utcnow()
        stats = {"summarized": 0, "archived": 0}
        
        # 1. Episodes > 90 days: remove detail entirely
        archive_cutoff = now - timedelta(days=self.ARCHIVE_AFTER_DAYS)
        old_episodes = await self._query_episodes(
            session,
            ended_before=archive_cutoff,
            has_detail=True,
        )
        for ep in old_episodes:
            if not ep.summary:
                # Safety: don't archive without summary
                logger.warning("Episode %s has no summary, skipping archive", ep.id)
                continue
            await self._clear_detail(ep.id, session)
            stats["archived"] += 1
        
        # 2. Episodes 30-90 days: trim detail to first 2000 chars
        summarize_cutoff = now - timedelta(days=self.SUMMARIZE_AFTER_DAYS)
        aging_episodes = await self._query_episodes(
            session,
            ended_before=summarize_cutoff,
            ended_after=archive_cutoff,
            detail_longer_than=2000,
        )
        for ep in aging_episodes:
            await self._trim_detail(ep.id, max_chars=2000, session=session)
            stats["summarized"] += 1
        
        return stats
```

### 3. Stale Fact Cleaner

```python
class StaleFactCleaner(MaintenanceTask):
    name = "stale_fact_cleaner"
    
    async def run(self, session: AsyncSession) -> dict:
        stats = {"deactivated": 0}
        
        # Deactivate facts that are superseded AND have no active references
        superseded = await self._query_facts(
            session,
            active=True,
            has_superseded_by=True,
        )
        for fact in superseded:
            await self._deactivate_fact(fact.id, session)
            stats["deactivated"] += 1
        
        return stats
```

### 4. Procedure Reviewer

```python
class ProcedureReviewer(MaintenanceTask):
    name = "procedure_reviewer"
    
    MIN_ACTIVATIONS = 5
    EFFECTIVENESS_THRESHOLD = 0.40
    
    async def run(self, session: AsyncSession) -> dict:
        stats = {"flagged": 0}
        
        procedures = await self._query_procedures(session, active=True)
        for proc in procedures:
            if proc.activation_count < self.MIN_ACTIVATIONS:
                continue
            
            effectiveness = proc.success_count / proc.activation_count
            if effectiveness < self.EFFECTIVENESS_THRESHOLD:
                await self._flag_for_review(proc.id, effectiveness, session)
                stats["flagged"] += 1
        
        return stats
```

### 5. Censor Retirer

```python
class CensorRetirer(MaintenanceTask):
    name = "censor_retirer"
    
    MIN_ACTIVATIONS = 5
    FALSE_POSITIVE_THRESHOLD = 0.50
    
    async def run(self, session: AsyncSession) -> dict:
        stats = {"retired": 0}
        
        censors = await self._query_censors(session, active=True)
        for censor in censors:
            if censor.activation_count < self.MIN_ACTIVATIONS:
                continue
            
            fp_rate = censor.false_positive_count / censor.activation_count
            if fp_rate > self.FALSE_POSITIVE_THRESHOLD:
                await self._retire_censor(censor.id, session)
                stats["retired"] += 1
        
        return stats
```

### 6. Memory Health Snapshot

```python
class MemoryHealthSnapshot(MaintenanceTask):
    name = "health_snapshot"
    
    async def run(self, session: AsyncSession) -> dict:
        """Collect memory health metrics for monitoring."""
        return {
            "facts": {
                "total": await self._count_facts(session),
                "active": await self._count_facts(session, active=True),
                "superseded": await self._count_facts(session, has_superseded_by=True),
            },
            "episodes": {
                "total": await self._count_episodes(session),
                "active": await self._count_episodes(session, has_detail=True),
                "archived": await self._count_episodes(session, has_detail=False),
            },
            "procedures": {
                "total": await self._count_procedures(session),
                "effective": await self._count_procedures(session, effectiveness_above=0.4),
            },
            "censors": {
                "total": await self._count_censors(session),
                "active": await self._count_censors(session, active=True),
            },
        }
```

---

## Schema Changes

```sql
-- 010_maintenance_state.sql

-- Maintenance state tracking
CREATE TABLE IF NOT EXISTS system.maintenance_state (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    agent_id TEXT NOT NULL,
    last_run TIMESTAMPTZ,
    last_reason TEXT,         -- 'catch-up', 'periodic', 'manual'
    last_results JSONB,       -- results from each task
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(agent_id)
);

-- Maintenance history (audit trail)
CREATE TABLE IF NOT EXISTS system.maintenance_history (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    agent_id TEXT NOT NULL,
    run_at TIMESTAMPTZ DEFAULT NOW(),
    reason TEXT NOT NULL,
    duration_ms INTEGER,
    results JSONB,
    errors JSONB
);

CREATE INDEX IF NOT EXISTS idx_maintenance_history_agent
    ON system.maintenance_history(agent_id, run_at DESC);
```

---

## Configuration

```python
class MaintenanceConfig:
    interval_hours: int = 12              # How often periodic runs
    episode_summarize_days: int = 30      # Trim detail after N days
    episode_archive_days: int = 90        # Remove detail after N days
    episode_detail_max_chars: int = 2000  # Max detail after trim
    procedure_min_activations: int = 5    # Min uses before reviewing
    procedure_effectiveness_threshold: float = 0.40
    censor_min_activations: int = 5
    censor_false_positive_threshold: float = 0.50
```

Configurable via environment variables:
- `NOUS_MAINTENANCE_INTERVAL_HOURS` (default: 12)
- `NOUS_EPISODE_SUMMARIZE_DAYS` (default: 30)
- `NOUS_EPISODE_ARCHIVE_DAYS` (default: 90)

---

## Integration Points

### Startup (runner.py or app initialization)

```python
# After Heart is initialized
maintenance = MaintenanceEngine(heart, config.maintenance)
await maintenance.start(session_factory)

# On shutdown
await maintenance.stop()
```

### Manual trigger (REST endpoint)

```python
@app.post("/maintenance/run")
async def run_maintenance():
    """Manually trigger a maintenance run."""
    results = await maintenance.run_now(reason="manual")
    return {"status": "completed", "results": results}
```

### Health check (REST endpoint)

```python
@app.get("/maintenance/status")
async def maintenance_status():
    """Return last run info + memory health."""
    return await maintenance.get_status()
```

---

## Testing Strategy

### Unit tests

- `test_episode_archiver.py` — 30d trim, 90d archive, skip-if-no-summary
- `test_stale_fact_cleaner.py` — deactivate superseded, skip active
- `test_procedure_reviewer.py` — flag low effectiveness, skip low activation count
- `test_censor_retirer.py` — retire high false-positive, skip low activation count
- `test_maintenance_engine.py` — catch-up on startup, periodic scheduling, task isolation (one failure doesn't block others)

### Integration tests

- Start engine with no prior state → runs catch-up
- Start engine with recent run → skips catch-up
- Full cycle: create episode → wait → archiver trims detail
- Task failure isolation: one task throws, others still run

---

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Maintenance blocks Nous during conversation | High | Run in background asyncio task, don't block request handling |
| Archiving removes episode detail before summary exists | High | Never archive without summary (safety check in archiver) |
| Procedure flagging is noisy early on | Low | MIN_ACTIVATIONS=5 threshold. Flag for review, don't auto-retire. |
| Clock skew on startup catch-up | Low | Use UTC everywhere. Overdue check has 1-hour grace period. |

---

## Success Criteria

- Maintenance runs at least once per 24 hours (periodic or catch-up)
- Episodes older than 90 days have no detail (only summary + metadata)
- No maintenance task failure blocks other tasks
- `/maintenance/status` returns accurate health snapshot
- After 3-day downtime, catch-up completes within 60 seconds of startup
