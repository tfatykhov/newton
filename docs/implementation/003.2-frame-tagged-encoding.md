# 003.2: Frame-Tagged Memory Encoding

**Status:** Shipped
**Priority:** P1 — Enables frame-aware retrieval in 005.1
**Estimated Effort:** 3-4 hours
**Prerequisites:** 003 (merged), 003.1 (merged), 004 (merged)
**Inspiration:** SRCM (Symbolic Recursive Compression Memory) codon tracking by Ghidorah-Prime

## Objective

Stamp every Heart memory (fact, episode, procedure) with the **active frame and active censors** at encode time. Then use this metadata during retrieval to boost memories encoded in a similar cognitive state to the current one.

SRCM stores metadata about active "codons" (behavioral patterns with fitness scores) alongside compressed vectors. Our equivalent: store the active frame + censors alongside each memory. This is cheap metadata that enables frame-aware retrieval — memories learned while debugging are more relevant when debugging again.

## Problem Statement

Currently, `Heart.learn()` and related methods have no awareness of *what the agent was doing* when it learned something. A fact learned during a "decision" frame about Postgres is stored identically to a fact learned during a "conversation" frame about Postgres. But the decision-frame fact likely contains more architectural nuance, while the conversation-frame fact is probably casual context. The retrieval engine can't distinguish them.

Episode already has `frame_used` — but facts and procedures don't, and none of them track active censors.

## Design Decisions

### D1: Two New Columns, Not a JSONB Blob

Add `encoded_frame VARCHAR(100)` and `encoded_censors JSONB` to facts and procedures. Episodes already have `frame_used`; add `encoded_censors` only. Separate columns over a JSONB blob because `encoded_frame` is a filter predicate — needs to be indexable.

### D2: Columns Are Nullable — Backward Compatible

Existing memories get NULL. No migration of historical data needed. Retrieval treats NULL as "no frame boost, no penalty" (neutral).

### D3: Frame Boost Is Multiplicative, Not Filtering

Don't *exclude* memories from other frames — just *boost* same-frame memories by 1.3x in relevance scoring. Cross-frame memories are often valuable (a procedure learned in debug mode applies in task mode too). The boost is a hint, not a gate.

### D4: Censor Overlap Scoring

For censors, compute Jaccard overlap between encoded censors and current active censors. Higher overlap → higher boost. This captures "similar cognitive constraints were active" — e.g., if "no-premature-optimization" was active when a fact was learned, and it's active now, that fact is probably more relevant to the current careful-evaluation mindset.

Formula: `censor_boost = 1.0 + 0.2 * jaccard(encoded_censors, active_censors)`

Range: 1.0 (no overlap) to 1.2 (perfect overlap). Deliberately modest — censors are a secondary signal.

### D5: Episode Compression Tiers (Schema Only)

Add `compression_tier VARCHAR(20) DEFAULT 'raw'` to episodes. Values: `raw`, `compressed`, `fossil`. Actual compression logic deferred to F008 (Memory Lifecycle) — this just adds the column so the schema is ready.

### D6: Pass Frame Context Through Heart API

`Heart.learn()`, `Heart.focus()` (working memory), and `Heart.recall()` accept optional `frame_id: str | None` and `active_censors: list[str] | None`. The CognitiveLayer passes these from its current frame selection.

## Schema Changes

### SQL Migration

```sql
-- Facts: add frame + censor encoding metadata
ALTER TABLE heart.facts ADD COLUMN encoded_frame VARCHAR(100);
ALTER TABLE heart.facts ADD COLUMN encoded_censors JSONB;
CREATE INDEX idx_facts_encoded_frame ON heart.facts (encoded_frame) WHERE encoded_frame IS NOT NULL;

-- Procedures: add frame + censor encoding metadata
ALTER TABLE heart.procedures ADD COLUMN encoded_frame VARCHAR(100);
ALTER TABLE heart.procedures ADD COLUMN encoded_censors JSONB;
CREATE INDEX idx_procedures_encoded_frame ON heart.procedures (encoded_frame) WHERE encoded_frame IS NOT NULL;

-- Episodes: add censor encoding (frame_used already exists) + compression tier
ALTER TABLE heart.episodes ADD COLUMN encoded_censors JSONB;
ALTER TABLE heart.episodes ADD COLUMN compression_tier VARCHAR(20) DEFAULT 'raw';
```

### ORM Changes: `nous/storage/models.py`

```python
# Fact model — add after 'tags':
encoded_frame: Mapped[str | None] = mapped_column(String(100))
encoded_censors = mapped_column(JSONB, nullable=True)

# Procedure model — add after 'tags':
encoded_frame: Mapped[str | None] = mapped_column(String(100))
encoded_censors = mapped_column(JSONB, nullable=True)

# Episode model — add after 'tags':
encoded_censors = mapped_column(JSONB, nullable=True)
compression_tier: Mapped[str | None] = mapped_column(String(20), server_default="'raw'")
```

### init.sql Updates

Add the new columns to the CREATE TABLE statements so fresh installs get them.

## Implementation

### Changes to `nous/heart/facts.py` (~20 lines)

Update `_learn()` to accept and store frame context:

```python
async def _learn(
    self,
    inp: FactInput,
    session: AsyncSession,
    *,
    check_contradictions: bool = True,
    encoded_frame: str | None = None,
    encoded_censors: list[str] | None = None,
) -> FactDetail:
    # ... existing dedup/contradiction logic ...
    
    fact = Fact(
        agent_id=self.agent_id,
        content=inp.content,
        # ... existing fields ...
        encoded_frame=encoded_frame,
        encoded_censors=encoded_censors,
    )
```

### Changes to `nous/heart/heart.py` (~15 lines)

Pass frame context through the public API:

```python
async def learn(
    self,
    content: str,
    *,
    category: str | None = None,
    source: str | None = None,
    tags: list[str] | None = None,
    confidence: float = 1.0,
    session: AsyncSession | None = None,
    check_contradictions: bool = True,
    encoded_frame: str | None = None,
    encoded_censors: list[str] | None = None,
) -> FactDetail:
```

Same pattern for `focus()` and episode/procedure creation methods.

### Changes to `nous/heart/search.py` (~30 lines)

Add frame-aware re-ranking:

```python
def apply_frame_boost(
    results: list,
    current_frame: str | None,
    current_censors: list[str] | None,
) -> list:
    """Re-rank results with frame and censor boost."""
    if not current_frame and not current_censors:
        return results
    
    for r in results:
        boost = 1.0
        
        # Frame boost (D3)
        encoded = getattr(r, "encoded_frame", None)
        if encoded and current_frame and encoded == current_frame:
            boost *= 1.3
        
        # Censor overlap boost (D4)
        enc_censors = set(getattr(r, "encoded_censors", None) or [])
        cur_censors = set(current_censors or [])
        if enc_censors and cur_censors:
            jaccard = len(enc_censors & cur_censors) / len(enc_censors | cur_censors)
            boost *= 1.0 + 0.2 * jaccard
        
        r._relevance_boost = boost
    
    # Re-sort by boosted score
    results.sort(key=lambda r: getattr(r, "_relevance_boost", 1.0), reverse=True)
    return results
```

### Changes to `nous/cognitive/layer.py` (~10 lines)

Pass frame context when CognitiveLayer calls Heart during post_turn:

```python
# In post_turn, when learning facts from the turn:
await self._heart.learn(
    fact_content,
    encoded_frame=turn_context.frame.frame_id,
    encoded_censors=turn_context.active_censors,
)
```

### Changes to `nous/cognitive/context.py` (~10 lines)

Apply frame boost after retrieval in `build()`:

```python
# After retrieving facts, before formatting:
from nous.heart.search import apply_frame_boost
facts = apply_frame_boost(facts, frame.frame_id, active_censor_names)
```

## Tests

### File: `tests/test_frame_tagged_encoding.py` (~100 lines)

| Test | What it verifies |
|------|-----------------|
| `test_learn_fact_with_frame` | Fact stored with encoded_frame |
| `test_learn_fact_with_censors` | Fact stored with encoded_censors JSONB |
| `test_learn_fact_no_frame_backward_compat` | Existing API still works (NULL frame) |
| `test_frame_boost_same_frame` | Same-frame memory boosted 1.3x |
| `test_frame_boost_different_frame` | Different-frame memory not boosted |
| `test_frame_boost_null_frame_neutral` | NULL encoded_frame → no boost/penalty |
| `test_censor_overlap_full` | Perfect censor overlap → 1.2x boost |
| `test_censor_overlap_partial` | 50% overlap → 1.1x boost |
| `test_censor_overlap_none` | No overlap → 1.0x (neutral) |
| `test_episode_compression_tier_default` | New episodes get tier='raw' |
| `test_procedure_frame_encoding` | Procedures also get frame metadata |

## Summary

| Component | Lines (est.) | Change Type |
|-----------|-------------|-------------|
| `models.py` | ~10 | Modified (3 models) |
| `facts.py` | ~20 | Modified |
| `heart.py` | ~15 | Modified (API signature) |
| `search.py` | ~30 | Modified (new function) |
| `layer.py` | ~10 | Modified |
| `context.py` | ~10 | Modified |
| `init.sql` | ~15 | Modified (new columns) |
| `test_frame_tagged_encoding.py` | ~100 | New |
| **Total** | **~210** | |

Small, backward-compatible change. All existing tests pass (new columns are nullable). Enables frame-aware retrieval for 005.1's smart context preparation.

## Relationship to Other Specs

- **005.1 (Smart Context)**: Uses frame boost in `ContextEngine.build()` — 003.2 provides the data
- **M1.3 / Issue #8 (Censor Learning)**: 003.2 stores censor state at encode time; M1.3 adds fitness evolution
- **F008 (Memory Lifecycle)**: `compression_tier` column enables future episode compression
- **SRCM inspiration**: Codon tracking → frame+censor tracking; fitness scores → deferred to M1.3
