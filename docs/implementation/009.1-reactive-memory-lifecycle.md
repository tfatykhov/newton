# Spec 009.1: Reactive Memory Lifecycle (Event-Driven)

**Status:** Draft
**Depends on:** F006 (Event Bus), F008 (Memory Lifecycle spec)
**Phase:** 1 of 4 (F008 implementation)

## Problem

Memory accumulates without self-management:

- **Duplicate facts** — same information stored multiple times with slightly different wording. Manual cleanup removed 35 garbage decisions and 8 stale facts (Feb 25). This should never require manual intervention.
- **Contradicting facts** — newer information stored alongside old, with no supersession. Both surface in context, confusing the agent.
- **Episodes close without summarization** — episodes end but retain raw detail indefinitely. No automatic fact extraction.
- **Censors don't escalate** — a `warn` censor that triggers repeatedly should become a `block`, but currently stays at `warn` forever.

### Root Cause

F008 specifies lifecycle transitions but none are implemented. The event bus (F006) exists and fires events, but no handlers drive memory state transitions.

---

## Architecture

### Event-Driven Transitions Only

This phase implements **immediate reactions** to memory events. No scheduler, no periodic tasks, no catch-up logic — those are Phase 2.

```
Event Bus (F006)
  │
  ├── fact_learned ──→ FactDeduplicator
  │     ├── Search for similar facts (embedding similarity)
  │     ├── > 0.95: Confirm existing fact (increment confirmation_count)
  │     ├── 0.85-0.95: LLM semantic check, confirm or store new
  │     └── < 0.85: Store as new fact
  │
  ├── fact_learned ──→ FactSupersessionChecker
  │     ├── Search for facts with same subject but different content
  │     ├── LLM check: does new fact contradict old?
  │     └── If yes: mark old fact superseded_by = new fact ID
  │
  ├── episode_closed ──→ EpisodeSummarizer
  │     ├── LLM generates title (if missing) + summary (100-150 words)
  │     ├── Extract key facts from summary → learn_fact() (triggers dedup)
  │     └── Link related decisions to episode
  │
  └── censor_triggered ──→ CensorEscalator
        ├── Increment activation_count
        ├── If activation_count >= escalation_threshold: warn → block
        └── Track false_positive_count for future retirement (Phase 2)
```

### Module Structure

```
nous/heart/
  ├── heart.py              — existing, add dedup to learn_fact()
  ├── lifecycle/
  │   ├── __init__.py
  │   ├── fact_dedup.py     — FactDeduplicator
  │   ├── fact_supersede.py — FactSupersessionChecker
  │   ├── episode_close.py  — EpisodeSummarizer
  │   └── censor_escalate.py — CensorEscalator
  └── ...
```

---

## Component Details

### 1. Fact Deduplication (on learn)

**Trigger:** `fact_learned` event (or inline in `Heart.learn_fact()`)

```python
class FactDeduplicator:
    CONFIRM_THRESHOLD = 0.95   # Direct confirm, no LLM needed
    CHECK_THRESHOLD = 0.85     # LLM semantic equivalence check
    
    async def check_and_deduplicate(
        self,
        new_content: str,
        new_subject: str | None,
        agent_id: str,
        session: AsyncSession,
    ) -> DeduplicationResult:
        """Returns action: 'confirm_existing' | 'store_new' | 'merge'."""
        
        # 1. Vector search for similar facts
        similar = await self._heart.search_facts(
            query=new_content,
            limit=5,
            agent_id=agent_id,
            session=session,
        )
        
        # 2. Check top result
        if not similar:
            return DeduplicationResult(action="store_new")
        
        top = similar[0]
        
        # 3. High similarity → confirm without LLM
        if top.score >= self.CONFIRM_THRESHOLD:
            await self._heart.confirm_fact(top.id, session=session)
            return DeduplicationResult(
                action="confirm_existing",
                existing_fact_id=top.id,
                similarity=top.score,
            )
        
        # 4. Medium similarity → LLM check
        if top.score >= self.CHECK_THRESHOLD:
            is_same = await self._llm_semantic_check(
                existing=top.content,
                new=new_content,
            )
            if is_same:
                await self._heart.confirm_fact(top.id, session=session)
                return DeduplicationResult(
                    action="confirm_existing",
                    existing_fact_id=top.id,
                    similarity=top.score,
                )
        
        # 5. Low similarity → store new
        return DeduplicationResult(action="store_new")
```

**Integration point:** Modify `Heart.learn_fact()` to call dedup *before* inserting. If dedup returns `confirm_existing`, skip the insert and return the existing fact.

**LLM semantic check prompt:**
```
Two facts about the same topic. Are they saying the same thing?

Existing: "{existing}"
New: "{new}"

Answer YES if they convey the same information (even if worded differently).
Answer NO if they contain meaningfully different information.
Answer only YES or NO.
```

**Cost:** ~100 tokens per check, only triggered for 0.85-0.95 similarity band. Expected <10% of learn_fact calls.

### 2. Fact Supersession (on learn)

**Trigger:** Same `fact_learned` event, runs after dedup determines `store_new`.

```python
class FactSupersessionChecker:
    SUBJECT_MATCH_THRESHOLD = 0.80
    
    async def check_contradiction(
        self,
        new_fact_id: str,
        new_content: str,
        new_subject: str | None,
        agent_id: str,
        session: AsyncSession,
    ) -> SupersessionResult:
        """Check if the new fact contradicts an existing one."""
        
        if not new_subject:
            return SupersessionResult(action="none")
        
        # 1. Find facts with similar subjects
        candidates = await self._heart.search_facts(
            query=new_subject,
            limit=10,
            agent_id=agent_id,
            active_only=True,
            session=session,
        )
        
        # 2. Filter to same-subject facts (not the new one)
        same_subject = [
            f for f in candidates
            if f.id != new_fact_id
            and f.subject
            and self._subject_similarity(f.subject, new_subject) > self.SUBJECT_MATCH_THRESHOLD
        ]
        
        if not same_subject:
            return SupersessionResult(action="none")
        
        # 3. LLM check for contradiction
        for existing in same_subject:
            contradicts = await self._llm_contradiction_check(
                existing=existing.content,
                new=new_content,
            )
            if contradicts:
                await self._heart.supersede_fact(
                    old_id=existing.id,
                    new_id=new_fact_id,
                    session=session,
                )
                return SupersessionResult(
                    action="superseded",
                    superseded_fact_id=existing.id,
                )
        
        return SupersessionResult(action="none")
```

**LLM contradiction check prompt:**
```
Do these two facts about "{subject}" contradict each other?

Existing: "{existing}"
New: "{new}"

Answer YES if the new fact updates, corrects, or replaces the existing one.
Answer NO if they are compatible (both can be true).
Answer only YES or NO.
```

### 3. Episode Auto-Summarize (on close)

**Trigger:** `episode_closed` event

```python
class EpisodeSummarizer:
    async def summarize_and_extract(
        self,
        episode_id: str,
        agent_id: str,
        session: AsyncSession,
    ) -> SummarizationResult:
        """Generate summary + extract facts from closed episode."""
        
        episode = await self._heart.get_episode(episode_id, session=session)
        if not episode or not episode.detail:
            return SummarizationResult(skipped=True, reason="no detail")
        
        # 1. Generate title + summary if missing
        if not episode.summary:
            title, summary = await self._llm_summarize(episode.detail)
            await self._heart.update_episode(
                episode_id,
                title=title,
                summary=summary,
                session=session,
            )
        
        # 2. Extract facts from summary
        facts = await self._llm_extract_facts(
            episode.summary or summary,
            episode.detail,
        )
        
        # 3. Learn each fact (triggers dedup automatically)
        learned_ids = []
        for fact in facts:
            result = await self._heart.learn_fact(
                content=fact.content,
                subject=fact.subject,
                source=f"episode:{episode_id}",
                agent_id=agent_id,
                session=session,
            )
            if result:
                learned_ids.append(result.id)
        
        return SummarizationResult(
            title=title,
            summary_length=len(summary),
            facts_extracted=len(facts),
            facts_learned=len(learned_ids),
        )
```

**Summarization prompt:**
```
Summarize this conversation episode in 100-150 words. Focus on:
- What was discussed / accomplished
- Key decisions made
- Important facts learned
- Outcome (success/failure/ongoing)

Also provide a short title (5-10 words).

Episode transcript:
{detail}
```

**Fact extraction prompt:**
```
Extract factual information from this episode that would be useful to remember long-term.
Return as JSON array: [{"subject": "topic", "content": "the fact"}]
Only include durable facts, not transient conversation details.
Limit to 5 most important facts.

Summary: {summary}
Detail: {detail}
```

### 4. Censor Escalation (on trigger)

**Trigger:** `censor_triggered` event

```python
class CensorEscalator:
    DEFAULT_ESCALATION_THRESHOLD = 5
    
    async def check_escalation(
        self,
        censor_id: str,
        was_blocked: bool,
        session: AsyncSession,
    ) -> EscalationResult:
        """Escalate warn → block if threshold reached."""
        
        censor = await self._heart.get_censor(censor_id, session=session)
        if not censor:
            return EscalationResult(action="none")
        
        # Only escalate warn → block
        if censor.severity != "warn":
            return EscalationResult(action="none")
        
        threshold = censor.escalation_threshold or self.DEFAULT_ESCALATION_THRESHOLD
        
        if censor.activation_count >= threshold:
            await self._heart.update_censor(
                censor_id,
                severity="block",
                session=session,
            )
            return EscalationResult(
                action="escalated",
                old_severity="warn",
                new_severity="block",
                activation_count=censor.activation_count,
            )
        
        return EscalationResult(action="none")
```

---

## Schema Changes

### New columns

```sql
-- Facts: track supersession chain
ALTER TABLE heart.facts
    ADD COLUMN IF NOT EXISTS superseded_by UUID REFERENCES heart.facts(id),
    ADD COLUMN IF NOT EXISTS source TEXT;  -- e.g., 'episode:uuid', 'conversation', 'user'

-- Censors: track escalation data
ALTER TABLE heart.censors
    ADD COLUMN IF NOT EXISTS escalation_threshold INTEGER DEFAULT 5,
    ADD COLUMN IF NOT EXISTS false_positive_count INTEGER DEFAULT 0;
```

### New Heart methods

```python
# Facts
async def confirm_fact(self, fact_id: str, session: AsyncSession) -> None:
    """Increment confirmation_count and update last_confirmed."""

async def supersede_fact(self, old_id: str, new_id: str, session: AsyncSession) -> None:
    """Mark old fact as superseded by new fact (set superseded_by, active=false)."""

# Episodes
async def update_episode(self, episode_id: str, *, title: str = None, summary: str = None, session: AsyncSession) -> None:
    """Update episode title and/or summary."""

# Censors
async def update_censor(self, censor_id: str, *, severity: str = None, session: AsyncSession) -> None:
    """Update censor severity (for escalation)."""
```

---

## Event Bus Integration

### New event handlers registered in `event_bus.py`

```python
# On startup, register lifecycle handlers
bus.subscribe("fact_learned", fact_deduplicator.on_fact_learned)
bus.subscribe("fact_learned", fact_supersession.on_fact_learned)  # runs after dedup
bus.subscribe("episode_closed", episode_summarizer.on_episode_closed)
bus.subscribe("censor_triggered", censor_escalator.on_censor_triggered)
```

### Event payloads (verify these exist or add them)

```python
# fact_learned — emitted by Heart.learn_fact()
{"fact_id": str, "content": str, "subject": str | None, "agent_id": str}

# episode_closed — emitted by Heart.close_episode()
{"episode_id": str, "agent_id": str}

# censor_triggered — emitted by CognitiveLayer censor check
{"censor_id": str, "was_blocked": bool, "agent_id": str}
```

**Verify:** Check which events F006 currently emits. Add any missing events to Heart methods.

---

## Migration

```sql
-- 009_reactive_lifecycle.sql

-- Facts: supersession tracking
ALTER TABLE heart.facts
    ADD COLUMN IF NOT EXISTS superseded_by UUID REFERENCES heart.facts(id),
    ADD COLUMN IF NOT EXISTS source TEXT;

-- Censors: escalation tracking
ALTER TABLE heart.censors
    ADD COLUMN IF NOT EXISTS escalation_threshold INTEGER DEFAULT 5,
    ADD COLUMN IF NOT EXISTS false_positive_count INTEGER DEFAULT 0;

-- Index for supersession queries
CREATE INDEX IF NOT EXISTS idx_facts_superseded_by ON heart.facts(superseded_by)
    WHERE superseded_by IS NOT NULL;
```

---

## Testing Strategy

### Unit tests

- `test_fact_dedup.py`
  - Similarity > 0.95 → confirm existing, don't create new
  - Similarity 0.85-0.95 + LLM says same → confirm existing
  - Similarity 0.85-0.95 + LLM says different → store new
  - Similarity < 0.85 → store new
  - No existing facts → store new

- `test_fact_supersede.py`
  - Same subject + contradicting content → supersede old
  - Same subject + compatible content → no action
  - Different subject → no action
  - No subject on new fact → skip check

- `test_episode_summarize.py`
  - Episode with detail → generates title + summary + extracts facts
  - Episode without detail → skips
  - Extracted facts trigger dedup (integration)

- `test_censor_escalate.py`
  - activation_count < threshold → no action
  - activation_count >= threshold + severity=warn → escalate to block
  - severity=block → no action (already escalated)

### Integration tests

- Learn duplicate fact → confirm_existing returned, no new row
- Learn contradicting fact → old fact marked superseded
- Close episode → summary generated, facts extracted and deduped
- Trigger censor 5 times → escalated from warn to block

---

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| LLM semantic check adds latency to learn_fact | Medium | Only 0.85-0.95 band triggers LLM (~10% of calls). Use fast model (sonnet). |
| False dedup (different facts marked as same) | High | Conservative threshold (0.95 for auto-confirm). LLM check for ambiguous zone. |
| False supersession (compatible facts marked contradicting) | High | LLM contradiction check with clear prompt. Log all supersessions for audit. |
| Episode summarization costs tokens | Low | Only on close, ~500 tokens per episode. Expected <10/day. |
| Missing events in event bus | Medium | Audit F006 event emissions in Phase 1 before building handlers. |

---

## Success Criteria

- Zero duplicate facts created when same information learned twice
- Contradicting facts automatically resolved (old superseded, new active)
- All closed episodes have title + summary within 30 seconds of close
- Censors escalate from warn → block after threshold activations
- No manual memory cleanup needed (was previously required monthly)

---

## Open Questions

1. **Should dedup run synchronously inside learn_fact() or async via event bus?**
   Recommendation: Synchronous inside learn_fact() — the caller needs to know if the fact was deduped. Event bus for supersession check (can be async, caller doesn't need the result).

2. **What model for LLM checks?**
   Recommendation: Same model as agent (claude-sonnet-4-6). Could use a cheaper model for simple yes/no checks but adds configuration complexity.

3. **Should superseded facts remain in search results?**
   Recommendation: No. Filter `active=true AND superseded_by IS NULL` in search queries. Superseded facts are still in the DB for audit trail.
