# 004.1: CEL Expression Guardrails — Implementation Plan

**Source Spec:** [004.1-cel-guardrails.md](004.1-cel-guardrails.md)
**Date:** 2026-02-23
**Review:** Pending 3-agent review (nous-arch, nous-minsky, nous-devil)

## Minsky Context

### Censors as Suppressor Agents (Ch. 9)

Guardrails are Minsky's censors — agents that suppress bad actions before they happen. The current JSONB evaluator is a primitive censor: it recognizes a fixed set of patterns and blocks. CEL transforms censors from pattern-matchers into expression-evaluators — closer to Minsky's vision of censors that can reason about context.

Key Minsky principles applied:

1. **Censors should suppress, not modify (Ch. 9.3).** CEL guardrails return block/warn — they don't transform the decision. The decision either passes or doesn't. This is correct behavior for a censor.

2. **Censors need context to be effective (Ch. 9.4).** The current guardrail system fails because it can't see enough context (only 4 hardcoded fields). CEL opens the full decision context to censors, making them actually useful.

3. **Administrative agents need flexibility (Ch. 10, Papert's Principle).** The JSONB evaluator requires code changes for every new guardrail condition. CEL makes guardrails data-driven — an administrative improvement that multiplies the value of existing knowledge.

4. **Parallel bundles for robust decisions (Ch. 18).** Multiple guardrails evaluate independently. A decision must survive ALL of them. This is a parallel bundle — failure of any single guardrail blocks the action. CEL makes it practical to have many guardrails (easy to write, cheap to evaluate).

### Multi-Agent Implications

When multiple Nous agents share a Brain (F013 future), guardrails must:
- Evaluate in the context of the requesting agent (not a global context)
- Support agent-specific variables in CEL (e.g., `agent.trust_level`)
- Not leak one agent's context to another's guardrail evaluation

The `decision.*` namespace is already scoped per-evaluation. For multi-agent, we'll add `agent.*` namespace later without breaking existing expressions.

## Architecture Review Questions

For the 3-agent review team:

### Architecture (nous-arch)
1. Is `cel-python` the right dependency? Alternatives? Risk of abandonment?
2. Should CEL compilation happen at guardrail load time (startup) or evaluation time (lazy)?
3. Is the `decision.*` namespace sufficient? Should we add `agent.*` now for future multi-agent?
4. How should CEL errors propagate? Fail-open is specified but has security implications.

### Minsky/Cognitive (nous-minsky)
1. Does CEL align with Minsky's censor model? Are there aspects of censors we're missing?
2. Should guardrails have priority ordering (Ch. 9 — "some censors should override others")?
3. Could CEL expressions reference other guardrails' results? (Ch. 18 — cross-connected networks)
4. How does this interact with the Cognitive Layer's frame-based guardrail bypass (creative frame has fewer censors)?

### Devil's Advocate (nous-devil)
1. What happens if cel-python has a security vulnerability? Sandboxing claims?
2. Can a malicious CEL expression cause DoS (infinite loop, memory exhaustion)?
3. What if legacy JSONB auto-conversion produces wrong CEL? Silent behavior change?
4. Program cache growth — unbounded? Memory leak potential?
5. What if a guardrail expression references a field that doesn't exist? Crash or false?

## Implementation Details

### CEL Environment Setup

```python
import celpy
from celpy import celtypes

# Shared environment — compiled once at module load
_CEL_ENV = celpy.Environment()

# Type declarations for the decision namespace
# CEL needs to know the structure for type checking
_DECISION_TYPE = celpy.Environment(
    annotations={
        "decision": celtypes.MapType,
    }
)
```

**Open question:** `cel-python` has two modes:
1. **Untyped** — `Environment()` with no annotations. Any field access works, but runtime errors on missing fields.
2. **Typed** — `Environment(annotations=...)` with Protobuf-like type declarations. Compile-time checking but requires schema maintenance.

Recommendation: Start untyped for flexibility, add type checking later.

### Activation Context Construction

```python
def _build_activation(
    description: str,
    stakes: str,
    confidence: float,
    category: str | None = None,
    tags: list[str] | None = None,
    reasons: list[dict] | None = None,
    pattern: str | None = None,
    quality_score: float | None = None,
    context: dict | None = None,
) -> dict[str, celtypes.Value]:
    """Build CEL activation with decision.* namespace."""
    decision_map = {
        "description": celtypes.StringType(description),
        "stakes": celtypes.StringType(stakes),
        "confidence": celtypes.DoubleType(confidence),
        "category": celtypes.StringType(category or ""),
        "tags": celtypes.ListType([celtypes.StringType(t) for t in (tags or [])]),
        "reason_count": celtypes.IntType(len(reasons or [])),
        "pattern": celtypes.StringType(pattern or ""),
        "quality_score": celtypes.DoubleType(quality_score if quality_score is not None else 0.0),
        "has_pattern": celtypes.BoolType(bool(pattern)),
        "has_tags": celtypes.BoolType(len(tags or []) > 0),
        "context": _dict_to_cel_map(context or {}),
    }
    return {"decision": celtypes.MapType(
        {celtypes.StringType(k): v for k, v in decision_map.items()}
    )}
```

### Legacy Conversion

```python
_JSONB_TO_CEL = {
    "stakes": lambda v: f"decision.stakes == '{v}'",
    "confidence_lt": lambda v: f"decision.confidence < {v}",
    "reason_count_lt": lambda v: f"decision.reason_count < {v}",
    "quality_lt": lambda v: f"decision.quality_score < {v}",
}

def _jsonb_to_cel(condition: dict) -> str:
    parts = []
    for key, value in condition.items():
        converter = _JSONB_TO_CEL.get(key)
        if converter:
            parts.append(converter(value))
        else:
            logger.warning("Unknown legacy condition key: %s", key)
    return " && ".join(parts) if parts else "false"
```

### Brain.check() Signature Update

```python
# Current:
async def check(self, description, stakes, confidence, tags, reasons, pattern, quality_score, session)

# New — add category + context:
async def check(self, description, stakes, confidence, category=None, tags=None, reasons=None, pattern=None, quality_score=None, context=None, session=None)
```

### Seed Data Migration

Current seed guardrails use JSONB:
```json
{"stakes": "high", "confidence_lt": 0.5}
```

New seed guardrails use CEL:
```json
{"cel": "decision.stakes == 'high' && decision.confidence < 0.5"}
```

**Migration strategy:** Don't change existing DB rows. Legacy auto-conversion handles them. Only new seed.sql uses CEL format. Users can migrate at their own pace.

## Test Plan

### Backward Compatibility (Critical)
```python
# test_legacy_jsonb_stakes — {"stakes": "high"} still blocks
# test_legacy_jsonb_confidence — {"confidence_lt": 0.5} still blocks
# test_legacy_jsonb_compound — {"stakes": "high", "confidence_lt": 0.5} still blocks
# test_legacy_jsonb_no_match — {"stakes": "high"} doesn't block medium stakes
```

### CEL Expressions
```python
# test_cel_string_condition — raw CEL string in condition column
# test_cel_dict_condition — {"cel": "expression"} format
# test_cel_context_access — decision.context.custom_field works
# test_cel_tags_size — size(decision.tags) > 0
# test_cel_has_pattern — decision.has_pattern boolean
# test_cel_in_operator — decision.stakes in ['high', 'critical']
# test_cel_contains — decision.description.contains('trading')
# test_cel_complex_and_or — (A && B) || C
# test_cel_negation — !decision.context.reviewed
```

### Error Handling
```python
# test_cel_invalid_syntax — bad expression → no block (fail open)
# test_cel_missing_field — decision.nonexistent → no block
# test_cel_type_mismatch — comparing string to int → no block
# test_cel_empty_condition — {} → no match (safe default)
```

### Performance
```python
# test_cel_program_cached — same expression only compiled once
# test_cel_many_guardrails — 20 guardrails evaluate in <50ms
```

## Risk Assessment

| Risk | Mitigation |
|------|------------|
| `cel-python` abandoned | Pure Python, we can fork. Simple enough to replace with custom evaluator. |
| CEL DoS (expensive expression) | CEL has no loops. Evaluation is O(expression_size). No infinite execution possible. |
| Silent behavior change from legacy conversion | Comprehensive backward-compat tests. Log all conversions at DEBUG level. |
| Cache memory growth | Cache keyed by expression string. Bounded by number of unique guardrails (~10-50). |
| Fail-open security gap | Log all eval failures. Monitor `guardrail_eval_error` events. Add circuit breaker if failure rate spikes. |

## Dependency Analysis

```
cel-python >= 0.4, < 1.0
├── google-re2 (optional, for regex)
├── lark-parser (for CEL grammar)
└── python-dateutil (for timestamp handling)
```

`lark-parser` is the main transitive dep. Well-maintained, widely used.

## Estimated Effort

- Guardrails rewrite: ~120 lines
- Brain.check() signature: ~10 lines
- Seed data update: ~20 lines
- Tests: ~200 lines
- **Total: ~350 lines, 2-3 hours**
