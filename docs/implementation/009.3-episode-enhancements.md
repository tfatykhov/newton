# Spec 009.3: Episode Enhancements (Composability & Queryability)

**Status:** Draft
**Depends on:** 009.1 (Reactive Lifecycle), 009.2 (Maintenance Engine)
**Phase:** 3 of 4 (F008 implementation)
**Research:** 016 (Memory Gap Analysis â€” G2: Episodic Indexing)

## Problem

Episodes are flat, isolated records. This limits their usefulness:

- **No compositionality** â€” A debugging session that spans 3 days creates 3 separate episodes with no link between them. The agent can't "replay" the arc.
- **No structured metadata** â€” Episodes have summary + detail (free text) but no structured fields for participants, tools used, entities involved, or key decisions. Search is limited to text similarity.
- **No chronological replay** â€” Heart's episode search returns results by embedding similarity, not temporal order. "What happened the last 3 times I debugged this?" requires chronological ordering.

### What F008 Already Covers

F008 defines episode *lifecycle* (ACTIVE â†’ SUMMARIZED â†’ ARCHIVED). Phase 2 implements that. This phase adds episode *structure and relationships* â€” orthogonal to lifecycle.

---

## Architecture

### Three Enhancements

```
1. EPISODE CHAINING (parent_episode_id)
   Episode A (Day 1: "Started debugging memory leak")
     â””â”€â”€ Episode B (Day 2: "Continued debugging, found root cause")
           â””â”€â”€ Episode C (Day 3: "Fixed and deployed")
   
   Each episode links to its parent. Query the chain to get full arc.

2. STRUCTURED METADATA (metadata JSONB)
   {
     "participants": ["Tim", "Emerson"],
     "tools_used": ["bash", "web_search", "recall_deep"],
     "entities": ["cognition-engines", "CSTP server"],
     "key_decisions": ["dec-uuid-1", "dec-uuid-2"],
     "outcome": "success",
     "tags": ["debugging", "memory", "production"]
   }

3. TEMPORAL SEQUENCE QUERIES
   get_episode_sequence(topic, limit) â†’ chronological replay
   get_episode_chain(episode_id) â†’ full parent chain
```

### Module Changes

```
nous/heart/
  â”œâ”€â”€ heart.py              â€” add chain + sequence query methods
  â”œâ”€â”€ schemas.py            â€” update EpisodeState with new fields
  â””â”€â”€ lifecycle/
      â””â”€â”€ episode_close.py  â€” enhance to extract metadata on close
```

---

## Component Details

### 1. Episode Chaining

**Schema change:**

```sql
ALTER TABLE heart.episodes
    ADD COLUMN IF NOT EXISTS parent_episode_id UUID REFERENCES heart.episodes(id);

CREATE INDEX IF NOT EXISTS idx_episodes_parent
    ON heart.episodes(parent_episode_id) WHERE parent_episode_id IS NOT NULL;
```

**How parent gets set:**

Option A â€” Agent explicitly links: `start_episode(topic, parent_id=prev_episode_id)`
Option B â€” Auto-detect: On `start_episode()`, search for recent closed episodes with similar topic. If similarity > 0.85 and closed within 48 hours, auto-link.

**Recommendation:** Option B (auto-detect) with Option A as override. The agent shouldn't have to manually track parent IDs.

```python
async def start_episode(
    self,
    input: EpisodeInput,
    parent_episode_id: str | None = None,  # explicit override
    session: AsyncSession,
) -> EpisodeState:
    # Auto-detect parent if not explicitly provided
    if parent_episode_id is None:
        parent_episode_id = await self._detect_parent_episode(
            topic=input.topic,
            session_id=input.session_id,
            session=session,
        )
    
    # Create episode with parent link
    ...

async def _detect_parent_episode(
    self,
    topic: str,
    session_id: str,
    session: AsyncSession,
) -> str | None:
    """Find a recent closed episode on the same topic to chain to."""
    cutoff = datetime.utcnow() - timedelta(hours=48)
    
    candidates = await self._search_episodes(
        query=topic,
        limit=3,
        ended_after=cutoff,
        session=session,
    )
    
    if candidates and candidates[0].score > 0.85:
        return str(candidates[0].id)
    
    return None
```

**Chain query:**

```python
async def get_episode_chain(
    self,
    episode_id: str,
    session: AsyncSession,
) -> list[EpisodeState]:
    """Walk up the parent chain and return episodes root-first."""
    chain = []
    current_id = episode_id
    seen = set()  # cycle protection
    
    while current_id and current_id not in seen:
        seen.add(current_id)
        ep = await self.get_episode(current_id, session=session)
        if ep is None:
            break
        chain.append(ep)
        current_id = ep.parent_episode_id
    
    chain.reverse()  # root first
    return chain
```

### 2. Structured Metadata

**Schema change:**

```sql
ALTER TABLE heart.episodes
    ADD COLUMN IF NOT EXISTS metadata JSONB DEFAULT '{}';
```

**Note:** Check if `structured_summary` column already serves this purpose. If it exists and is unused or underused, repurpose it instead of adding a new column.

**Auto-extraction on episode close (extends 009.1 EpisodeSummarizer):**

```python
async def _extract_metadata(
    self,
    episode_detail: str,
    episode_summary: str,
) -> dict:
    """LLM extracts structured metadata from episode content."""
    
    prompt = f"""Extract structured metadata from this episode.
Return JSON only:
{{
  "participants": ["list of people/agents involved"],
  "tools_used": ["list of tools/commands used"],
  "entities": ["list of projects/systems/concepts discussed"],
  "tags": ["3-5 keyword tags"],
  "outcome": "success | failure | partial | ongoing | unknown"
}}

Summary: {episode_summary}
Detail (first 2000 chars): {episode_detail[:2000]}"""
    
    response = await self._llm_call(prompt)
    return json.loads(response)
```

**Integration with EpisodeSummarizer (009.1):**

Add metadata extraction step after summarization:

```python
# In EpisodeSummarizer.summarize_and_extract()
# After generating summary, before extracting facts:
metadata = await self._extract_metadata(episode.detail, summary)
await self._heart.update_episode(
    episode_id,
    metadata=metadata,
    session=session,
)
```

### 3. Temporal Sequence Queries

```python
async def get_episode_sequence(
    self,
    topic: str,
    limit: int = 10,
    agent_id: str | None = None,
    session: AsyncSession,
) -> list[EpisodeState]:
    """Return episodes related to topic, ordered chronologically.
    
    Unlike search_episodes (which returns by similarity), this returns
    episodes that match the topic ordered by started_at ASC.
    Useful for replaying the history of a topic.
    """
    # 1. Semantic search for candidate episodes
    candidates = await self._search_episodes(
        query=topic,
        limit=limit * 2,  # over-fetch, then sort
        agent_id=agent_id,
        session=session,
    )
    
    # 2. Filter by minimum relevance
    relevant = [ep for ep in candidates if ep.score > 0.5]
    
    # 3. Sort chronologically
    relevant.sort(key=lambda ep: ep.started_at or datetime.min)
    
    return relevant[:limit]
```

**New Heart tool (for agent use):**

```python
# In tools.py â€” expose as agent-callable tool
async def replay_topic(topic: str, limit: int = 5) -> str:
    """Replay the history of a topic across episodes, chronologically."""
    episodes = await heart.get_episode_sequence(topic, limit=limit, session=session)
    
    if not episodes:
        return f"No episodes found for topic: {topic}"
    
    lines = [f"ðŸ“œ Episode history for '{topic}' ({len(episodes)} episodes):\n"]
    for ep in episodes:
        date = ep.started_at.strftime("%Y-%m-%d") if ep.started_at else "unknown"
        parent = f" (continues from {ep.parent_episode_id[:8]})" if ep.parent_episode_id else ""
        lines.append(f"â€¢ [{date}] {ep.title or 'Untitled'}{parent}")
        if ep.summary:
            lines.append(f"  {ep.summary[:200]}")
        if ep.metadata:
            tags = ep.metadata.get("tags", [])
            outcome = ep.metadata.get("outcome", "unknown")
            if tags:
                lines.append(f"  Tags: {', '.join(tags)} | Outcome: {outcome}")
        lines.append("")
    
    return "\n".join(lines)
```

---

## Migration

```sql
-- 011_episode_enhancements.sql

-- Episode chaining
ALTER TABLE heart.episodes
    ADD COLUMN IF NOT EXISTS parent_episode_id UUID REFERENCES heart.episodes(id);

-- Structured metadata
ALTER TABLE heart.episodes
    ADD COLUMN IF NOT EXISTS metadata JSONB DEFAULT '{}';

-- Indexes
CREATE INDEX IF NOT EXISTS idx_episodes_parent
    ON heart.episodes(parent_episode_id) WHERE parent_episode_id IS NOT NULL;

CREATE INDEX IF NOT EXISTS idx_episodes_metadata
    ON heart.episodes USING GIN(metadata) WHERE metadata != '{}';

-- Chronological queries
CREATE INDEX IF NOT EXISTS idx_episodes_started_at
    ON heart.episodes(agent_id, started_at DESC);
```

---

## Testing Strategy

### Unit tests

- `test_episode_chaining.py`
  - Auto-detect parent from similar recent episode
  - No parent when topic is different
  - No parent when gap > 48 hours
  - Explicit parent_id overrides auto-detect
  - get_episode_chain returns root-first order
  - Cycle protection in chain walk

- `test_episode_metadata.py`
  - Metadata extracted on episode close
  - Missing detail â†’ empty metadata
  - Metadata stored as JSONB, queryable

- `test_episode_sequence.py`
  - Returns episodes chronologically
  - Filters by minimum relevance
  - Over-fetches and trims to limit

### Integration tests

- Create 3 episodes on same topic across days â†’ auto-chained
- Close episode â†’ metadata extracted alongside summary
- Query "what happened with debugging?" â†’ chronological replay

---

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Auto-parent detection false positives | Medium | High threshold (0.85) + 48h window. Agent can override. |
| Metadata extraction adds latency on close | Low | Already doing LLM summarization on close (009.1). One more extraction call, ~200 tokens. |
| JSONB metadata schema drift | Low | No strict schema enforcement â€” treat as best-effort enrichment. |
| Long chains hurt performance | Low | Cycle protection + practical limit (episodes rarely chain beyond 5-10). |

---

## Success Criteria

- Multi-day projects auto-chain into episode arcs
- `replay_topic("debugging memory leak")` returns chronological episode history
- Episode metadata enables filtering by tools used, participants, outcome
- No manual episode linking required for common workflows
