"""Tests for 006 Event Bus — EventBus core, handlers, transcript, user tagging.

48 test cases across 8 test classes:
- TestEventBus (8): Core bus mechanics
- TestEpisodeSummarizer (7): Episode summary handler
- TestFactExtractor (12): Fact extraction handler (#45: +2 for threshold change, 008.4: +4 candidate_facts)
- TestTranscriptCapture (3): Transcript accumulation in SessionMetadata
- TestUserTagging (3): F010.5 user-tagged episodes
- TestSessionTimeoutMonitor (7): Session timeout detection
- TestSleepHandler (8): Sleep mode — reflection, compaction, pruning
- TestReviewFixes (4): Additional review-fix tests
"""

from __future__ import annotations

import asyncio
import json
import time
from unittest.mock import AsyncMock, MagicMock, patch
from uuid import uuid4

import httpx
import pytest

from nous.cognitive.schemas import SessionMetadata
from nous.events import Event, EventBus
from nous.heart.schemas import EpisodeInput, FactInput, FactSummary


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------


def _make_event(
    event_type: str = "test_event",
    agent_id: str = "test-agent",
    data: dict | None = None,
    session_id: str | None = "sess-1",
) -> Event:
    return Event(
        type=event_type,
        agent_id=agent_id,
        data=data or {},
        session_id=session_id,
    )


def _mock_settings(**overrides) -> MagicMock:
    """MagicMock Settings to avoid pydantic validation."""
    s = MagicMock()
    s.background_model = "claude-sonnet-4-5-20250514"
    s.anthropic_api_key = "sk-ant-test-key"
    s.anthropic_auth_token = ""
    s.session_idle_timeout = 1800
    s.sleep_timeout = 7200
    s.sleep_check_interval = 60
    s.event_bus_enabled = True
    s.episode_summary_enabled = True
    s.fact_extraction_enabled = True
    s.sleep_enabled = True
    for k, v in overrides.items():
        setattr(s, k, v)
    return s


def _mock_httpx_response(status_code: int = 200, body: dict | None = None) -> httpx.Response:
    """Build a mock httpx.Response."""
    resp = httpx.Response(
        status_code=status_code,
        json=body or {},
        request=httpx.Request("POST", "https://api.anthropic.com/v1/messages"),
    )
    return resp


def _llm_response(text: str) -> dict:
    """Wrap text in Anthropic Messages API response shape."""
    return {"content": [{"type": "text", "text": text}]}


# ===========================================================================
# TestEventBus — 8 tests
# ===========================================================================


class TestEventBus:
    """Core event bus tests using REAL EventBus."""

    @pytest.mark.asyncio
    async def test_emit_handler_receives_event(self):
        """1. emit + handler receives event."""
        bus = EventBus()
        received: list[Event] = []

        async def handler(event: Event) -> None:
            received.append(event)

        bus.on("test_event", handler)
        await bus.start()
        try:
            event = _make_event()
            await bus.emit(event)
            # Give bus time to process
            await asyncio.sleep(0.1)
            assert len(received) == 1
            assert received[0].type == "test_event"
            assert received[0].agent_id == "test-agent"
        finally:
            await bus.stop()

    @pytest.mark.asyncio
    async def test_multiple_handlers_same_event(self):
        """2. Multiple handlers for same event type."""
        bus = EventBus()
        results: list[str] = []

        async def handler_a(event: Event) -> None:
            results.append("a")

        async def handler_b(event: Event) -> None:
            results.append("b")

        bus.on("test_event", handler_a)
        bus.on("test_event", handler_b)
        await bus.start()
        try:
            await bus.emit(_make_event())
            await asyncio.sleep(0.1)
            assert "a" in results
            assert "b" in results
            assert len(results) == 2
        finally:
            await bus.stop()

    @pytest.mark.asyncio
    async def test_handler_error_doesnt_crash_bus(self):
        """3. Handler error doesn't crash bus (test with handler that raises Exception)."""
        bus = EventBus()
        received: list[Event] = []

        async def bad_handler(event: Event) -> None:
            raise ValueError("boom")

        async def good_handler(event: Event) -> None:
            received.append(event)

        bus.on("test_event", bad_handler)
        bus.on("other_event", good_handler)
        await bus.start()
        try:
            await bus.emit(_make_event("test_event"))
            await asyncio.sleep(0.1)
            # Bus still running — emit another event
            await bus.emit(_make_event("other_event"))
            await asyncio.sleep(0.1)
            assert len(received) == 1
        finally:
            await bus.stop()

    @pytest.mark.asyncio
    async def test_handler_error_doesnt_block_other_handlers(self):
        """4. Handler error doesn't block other handlers (error handler + good handler)."""
        bus = EventBus()
        results: list[str] = []

        async def bad_handler(event: Event) -> None:
            raise RuntimeError("fail")

        async def good_handler(event: Event) -> None:
            results.append("ok")

        bus.on("test_event", bad_handler)
        bus.on("test_event", good_handler)
        await bus.start()
        try:
            await bus.emit(_make_event())
            await asyncio.sleep(0.1)
            assert results == ["ok"]
        finally:
            await bus.stop()

    @pytest.mark.asyncio
    async def test_queue_full_drops_event(self):
        """5. Queue full drops event (max_queue=1, emit 2 events before processing)."""
        bus = EventBus(max_queue=1)
        # Don't start bus — events won't be processed, queue fills up
        await bus.emit(_make_event("first"))
        assert bus.pending == 1
        # Second emit should be dropped (queue full)
        await bus.emit(_make_event("second"))
        assert bus.pending == 1  # Still 1, second was dropped

    @pytest.mark.asyncio
    async def test_stop_drains_remaining_events(self):
        """6. stop() drains remaining events."""
        bus = EventBus()
        received: list[Event] = []

        async def handler(event: Event) -> None:
            received.append(event)

        bus.on("test_event", handler)
        # Don't start the bus — put events in queue manually
        await bus.emit(_make_event("test_event", data={"n": 1}))
        await bus.emit(_make_event("test_event", data={"n": 2}))
        assert bus.pending == 2

        # Start then immediately stop — stop() should drain
        await bus.start()
        await bus.stop()

        # All events should have been drained
        assert bus.pending == 0

    @pytest.mark.asyncio
    async def test_db_persister_called_for_every_event(self):
        """7. DB persister called for every event."""
        bus = EventBus()
        persisted: list[Event] = []

        async def mock_persister(event: Event) -> None:
            persisted.append(event)

        bus.set_db_persister(mock_persister)
        await bus.start()
        try:
            await bus.emit(_make_event("event_a"))
            await bus.emit(_make_event("event_b"))
            await asyncio.sleep(0.1)
            assert len(persisted) == 2
            assert persisted[0].type == "event_a"
            assert persisted[1].type == "event_b"
        finally:
            await bus.stop()

    @pytest.mark.asyncio
    async def test_unknown_event_type_no_error(self):
        """8. Unknown event type -- no handlers, no error."""
        bus = EventBus()
        await bus.start()
        try:
            # Emit event with no registered handlers
            await bus.emit(_make_event("unknown_event_type"))
            await asyncio.sleep(0.1)
            # Bus should still be running fine
            assert bus._running is True
        finally:
            await bus.stop()


# ===========================================================================
# TestEpisodeSummarizer — 7 tests
# ===========================================================================


class TestEpisodeSummarizer:
    """Episode summary handler tests."""

    def _make_summarizer(self, heart=None, settings=None, bus=None, http_client=None):
        from nous.handlers.episode_summarizer import EpisodeSummarizer

        heart = heart or AsyncMock()
        settings = settings or _mock_settings()
        bus = bus or MagicMock(spec=EventBus)
        bus.on = MagicMock()
        bus.emit = AsyncMock()
        http_client = http_client or AsyncMock(spec=httpx.AsyncClient)
        summarizer = EpisodeSummarizer(heart, settings, bus, http_client)
        return summarizer, heart, bus, http_client

    @pytest.mark.asyncio
    async def test_generates_summary_on_session_ended(self):
        """9. Generates summary on session_ended with transcript (mock httpx response)."""
        summary_json = {
            "title": "Test Session",
            "summary": "A test conversation about testing.",
            "key_points": ["point 1"],
            "outcome": "resolved",
            "topics": ["testing"],
        }
        summarizer, heart, bus, http_client = self._make_summarizer()
        heart.get_episode = AsyncMock(
            return_value=MagicMock(summary="opening msg", structured_summary=None)
        )
        heart.update_episode_summary = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(summary_json)))
        )

        episode_id = str(uuid4())
        event = _make_event(
            "session_ended",
            data={
                "episode_id": episode_id,
                "transcript": "User: Hello world\n\nAssistant: Hi there, how can I help you today?",
            },
        )
        await summarizer.handle(event)

        heart.update_episode_summary.assert_called_once()
        call_args = heart.update_episode_summary.call_args
        assert str(call_args[0][0]) == episode_id
        assert call_args[0][1]["title"] == "Test Session"

    @pytest.mark.asyncio
    async def test_skips_short_transcripts(self):
        """10. Skips short transcripts (<50 chars)."""
        summarizer, heart, bus, http_client = self._make_summarizer()
        heart.get_episode = AsyncMock(
            return_value=MagicMock(summary="hi", structured_summary=None)
        )

        event = _make_event(
            "session_ended",
            data={"episode_id": str(uuid4()), "transcript": "Hi"},
        )
        await summarizer.handle(event)

        heart.update_episode_summary.assert_not_called()

    @pytest.mark.asyncio
    async def test_skips_when_no_episode_id(self):
        """11. Skips when no episode_id in event."""
        summarizer, heart, bus, http_client = self._make_summarizer()

        event = _make_event("session_ended", data={"transcript": "some text" * 20})
        await summarizer.handle(event)

        heart.get_episode.assert_not_called()

    @pytest.mark.asyncio
    async def test_emits_episode_summarized_downstream(self):
        """12. Emits episode_summarized event downstream."""
        summary_json = {
            "title": "Summary",
            "summary": "Summarized.",
            "key_points": [],
            "outcome": "resolved",
            "topics": [],
        }
        summarizer, heart, bus, http_client = self._make_summarizer()
        heart.get_episode = AsyncMock(
            return_value=MagicMock(summary="opening", structured_summary=None)
        )
        heart.update_episode_summary = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(summary_json)))
        )

        episode_id = str(uuid4())
        event = _make_event(
            "session_ended",
            data={
                "episode_id": episode_id,
                "transcript": "User: This is a long enough transcript for testing purposes " * 3,
            },
        )
        await summarizer.handle(event)

        bus.emit.assert_called_once()
        emitted = bus.emit.call_args[0][0]
        assert emitted.type == "episode_summarized"
        assert emitted.data["episode_id"] == episode_id
        assert emitted.data["summary"]["title"] == "Summary"

    @pytest.mark.asyncio
    async def test_handles_llm_failure_gracefully(self):
        """13. Handles LLM failure gracefully (mock 500 response)."""
        summarizer, heart, bus, http_client = self._make_summarizer()
        heart.get_episode = AsyncMock(
            return_value=MagicMock(summary="opening", structured_summary=None)
        )
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(500, {"error": "internal"})
        )

        event = _make_event(
            "session_ended",
            data={
                "episode_id": str(uuid4()),
                "transcript": "A sufficiently long transcript for the summarizer to process" * 2,
            },
        )
        # Should not raise
        await summarizer.handle(event)

        heart.update_episode_summary.assert_not_called()
        bus.emit.assert_not_called()

    @pytest.mark.asyncio
    async def test_truncates_long_transcripts(self):
        """14. Truncates long transcripts (>8000 chars)."""
        summarizer, heart, bus, http_client = self._make_summarizer()
        heart.get_episode = AsyncMock(
            return_value=MagicMock(summary="opening", structured_summary=None)
        )
        heart.update_episode_summary = AsyncMock()

        summary_json = {"title": "T", "summary": "S", "key_points": [], "outcome": "resolved", "topics": []}
        captured_prompts: list[str] = []

        async def capture_post(url, **kwargs):
            body = kwargs.get("json", {})
            msg_content = body.get("messages", [{}])[0].get("content", "")
            captured_prompts.append(msg_content)
            return _mock_httpx_response(200, _llm_response(json.dumps(summary_json)))

        http_client.post = capture_post

        # Use turns separated by \n\n so truncation can split them
        long_transcript = "\n\n".join([f"User: Turn {i} " + "x" * 400 for i in range(30)])
        event = _make_event(
            "session_ended",
            data={"episode_id": str(uuid4()), "transcript": long_transcript},
        )
        await summarizer.handle(event)

        # The prompt sent to LLM should be truncated (shorter than original)
        assert len(captured_prompts) == 1
        assert len(captured_prompts[0]) < len(long_transcript)

    @pytest.mark.asyncio
    async def test_summary_includes_new_fields(self):
        """008.4: Summary includes outcome_rationale and candidate_facts."""
        summary_json = {
            "title": "Architecture Discussion",
            "summary": "Discussed project architecture and chose PostgreSQL.",
            "key_points": ["PostgreSQL chosen for pgvector support and unified storage"],
            "outcome": "resolved",
            "outcome_rationale": "User's question was fully answered with a concrete decision",
            "topics": ["architecture", "database"],
            "candidate_facts": ["Project uses PostgreSQL 17 with pgvector for embeddings"],
        }
        summarizer, heart, bus, http_client = self._make_summarizer()
        heart.get_episode = AsyncMock(
            return_value=MagicMock(summary="opening", structured_summary=None)
        )
        heart.update_episode_summary = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(summary_json)))
        )

        episode_id = str(uuid4())
        event = _make_event(
            "session_ended",
            data={
                "episode_id": episode_id,
                "transcript": "User: What database should we use?\n\nAssistant: I recommend PostgreSQL with pgvector." * 3,
            },
        )
        await summarizer.handle(event)

        # Verify summary stored with new fields
        heart.update_episode_summary.assert_called_once()
        stored_summary = heart.update_episode_summary.call_args[0][1]
        assert stored_summary["outcome_rationale"] == "User's question was fully answered with a concrete decision"
        assert stored_summary["candidate_facts"] == ["Project uses PostgreSQL 17 with pgvector for embeddings"]

        # Verify candidate_facts passed through in emitted event
        bus.emit.assert_called_once()
        emitted = bus.emit.call_args[0][0]
        assert emitted.data["candidate_facts"] == ["Project uses PostgreSQL 17 with pgvector for embeddings"]

    @pytest.mark.asyncio
    async def test_truncate_noop_under_limit(self):
        """008.4: Short transcript returned unchanged."""
        summarizer, _, _, _ = self._make_summarizer()
        short = "User: Hello\n\nAssistant: Hi there"
        result = summarizer._truncate_transcript(short)
        assert result == short

    @pytest.mark.asyncio
    async def test_truncate_preserves_first_last(self):
        """008.4: First and last turns always kept."""
        summarizer, _, _, _ = self._make_summarizer()
        turns = ["User: First turn"] + [f"Assistant: Middle turn {i} " + "x" * 500 for i in range(20)] + ["User: Last turn"]
        transcript = "\n\n".join(turns)
        result = summarizer._truncate_transcript(transcript, max_chars=2000)
        assert result.startswith("User: First turn")
        assert result.endswith("User: Last turn")

    @pytest.mark.asyncio
    async def test_truncate_prioritizes_decisions(self):
        """008.4: Decision turns kept over tool output."""
        summarizer, _, _, _ = self._make_summarizer()
        decision_turn = "Assistant: We decided to use PostgreSQL because it supports pgvector natively."
        tool_turn = "Tool output:\n```\n" + "x" * 600 + "\n```"
        filler = "Assistant: " + "y" * 400

        turns = ["User: Start"] + [tool_turn] * 5 + [decision_turn] + [filler] * 5 + ["User: End"]
        transcript = "\n\n".join(turns)
        result = summarizer._truncate_transcript(transcript, max_chars=3000)

        # Decision turn should be preserved
        assert "decided to use PostgreSQL" in result


# ===========================================================================
# TestFactExtractor — 6 tests
# ===========================================================================


class TestFactExtractor:
    """Fact extraction handler tests."""

    def _make_extractor(self, heart=None, settings=None, bus=None, http_client=None):
        from nous.handlers.fact_extractor import FactExtractor

        heart = heart or AsyncMock()
        settings = settings or _mock_settings()
        bus = bus or MagicMock(spec=EventBus)
        bus.on = MagicMock()
        bus.emit = AsyncMock()
        http_client = http_client or AsyncMock(spec=httpx.AsyncClient)
        extractor = FactExtractor(heart, settings, bus, http_client)
        return extractor, heart, bus, http_client

    @pytest.mark.asyncio
    async def test_extracts_facts_from_episode_summarized(self):
        """15. Extracts facts from episode_summarized (mock LLM response with facts JSON)."""
        facts_json = [
            {
                "subject": "user",
                "content": "User prefers dark mode",
                "category": "preference",
                "confidence": 0.9,
            },
        ]
        extractor, heart, bus, http_client = self._make_extractor()
        heart.search_facts = AsyncMock(return_value=[])  # No existing
        heart.learn = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(facts_json)))
        )

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {
                    "summary": "User discussed preferences.",
                    "key_points": ["prefers dark mode"],
                },
            },
        )
        await extractor.handle(event)

        heart.learn.assert_called_once()
        fact_input = heart.learn.call_args[0][0]
        assert isinstance(fact_input, FactInput)
        assert fact_input.content == "User prefers dark mode"

    @pytest.mark.asyncio
    async def test_deduplicates_with_score_above_085(self):
        """16. Deduplicates against existing facts using .score > 0.85 (#45: raised from 0.65)."""
        facts_json = [
            {"subject": "user", "content": "User likes Python", "category": "preference", "confidence": 0.9},
        ]
        extractor, heart, bus, http_client = self._make_extractor()

        # Return existing fact with .score above 0.85 threshold -> should be deduped
        existing_fact = MagicMock(spec=FactSummary)
        existing_fact.score = 0.90  # Above 0.85 threshold -> deduped
        heart.search_facts = AsyncMock(return_value=[existing_fact])
        heart.learn = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(facts_json)))
        )

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {"summary": "User likes Python.", "key_points": ["python"]},
            },
        )
        await extractor.handle(event)

        heart.learn.assert_not_called()  # Deduped — not stored

    @pytest.mark.asyncio
    async def test_allows_facts_with_score_between_065_and_085(self):
        """16b. Facts with score 0.65-0.85 pass through for supersession (#45)."""
        facts_json = [
            {"subject": "user", "content": "User likes Python 3.12", "category": "preference", "confidence": 0.9},
        ]
        extractor, heart, bus, http_client = self._make_extractor()

        # Return existing fact with .score in the 0.65-0.85 range -> should NOT be deduped
        existing_fact = MagicMock(spec=FactSummary)
        existing_fact.score = 0.70  # Between 0.65 and 0.85 -> allowed through
        heart.search_facts = AsyncMock(return_value=[existing_fact])
        heart.learn = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(facts_json)))
        )

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {"summary": "User likes Python 3.12.", "key_points": ["python"]},
            },
        )
        await extractor.handle(event)

        heart.learn.assert_called_once()  # Allowed through for supersession

    @pytest.mark.asyncio
    async def test_stores_fact_with_no_existing_match(self):
        """16c. Facts with no existing match are stored normally."""
        facts_json = [
            {"subject": "project", "content": "Project uses PostgreSQL", "category": "technical", "confidence": 0.85},
        ]
        extractor, heart, bus, http_client = self._make_extractor()

        heart.search_facts = AsyncMock(return_value=[])  # No existing match
        heart.learn = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(facts_json)))
        )

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {"summary": "Discussed project architecture.", "key_points": ["postgresql"]},
            },
        )
        await extractor.handle(event)

        heart.learn.assert_called_once()
        fact_input = heart.learn.call_args[0][0]
        assert isinstance(fact_input, FactInput)
        assert fact_input.content == "Project uses PostgreSQL"

    @pytest.mark.asyncio
    async def test_skips_low_confidence_facts(self):
        """17. Skips low-confidence facts (<0.6)."""
        facts_json = [
            {"subject": "user", "content": "Maybe likes Java", "category": "preference", "confidence": 0.4},
        ]
        extractor, heart, bus, http_client = self._make_extractor()
        heart.search_facts = AsyncMock(return_value=[])
        heart.learn = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(facts_json)))
        )

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {"summary": "Uncertain preferences.", "key_points": []},
            },
        )
        await extractor.handle(event)

        heart.learn.assert_not_called()

    @pytest.mark.asyncio
    async def test_max_5_facts_per_episode(self):
        """18. Max 5 facts per episode enforced."""
        facts_json = [
            {"subject": f"s{i}", "content": f"Fact {i}", "category": "technical", "confidence": 0.9}
            for i in range(8)  # 8 facts, only 5 should be stored
        ]
        extractor, heart, bus, http_client = self._make_extractor()
        heart.search_facts = AsyncMock(return_value=[])
        heart.learn = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(facts_json)))
        )

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {"summary": "Many facts.", "key_points": ["lots"]},
            },
        )
        await extractor.handle(event)

        assert heart.learn.call_count == 5

    @pytest.mark.asyncio
    async def test_handles_empty_summary(self):
        """19. Handles empty summary gracefully."""
        extractor, heart, bus, http_client = self._make_extractor()
        heart.learn = AsyncMock()

        event = _make_event(
            "episode_summarized",
            data={"episode_id": str(uuid4()), "summary": {}},
        )
        await extractor.handle(event)

        heart.learn.assert_not_called()

    @pytest.mark.asyncio
    async def test_handles_llm_failure(self):
        """20. Handles LLM failure gracefully."""
        extractor, heart, bus, http_client = self._make_extractor()
        heart.learn = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(500, {"error": "server error"})
        )

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {"summary": "Some summary.", "key_points": ["point"]},
            },
        )
        # Should not raise
        await extractor.handle(event)

        heart.learn.assert_not_called()

    @pytest.mark.asyncio
    async def test_uses_candidate_facts_skips_llm(self):
        """008.4: When candidate_facts present, store directly without LLM call."""
        extractor, heart, bus, http_client = self._make_extractor()
        heart.search_facts = AsyncMock(return_value=[])  # No duplicates
        heart.learn = AsyncMock()

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {
                    "summary": "Discussed architecture.",
                    "key_points": ["chose PostgreSQL"],
                },
                "candidate_facts": [
                    "Project uses PostgreSQL 17 with pgvector",
                    "Tim prefers direct architecture decisions",
                ],
            },
        )
        await extractor.handle(event)

        # LLM should NOT be called
        http_client.post.assert_not_called()
        # Both facts should be stored
        assert heart.learn.call_count == 2
        stored_contents = [call[0][0].content for call in heart.learn.call_args_list]
        assert "Project uses PostgreSQL 17 with pgvector" in stored_contents
        assert "Tim prefers direct architecture decisions" in stored_contents

    @pytest.mark.asyncio
    async def test_candidate_facts_deduped(self):
        """008.4: candidate_facts are deduped against existing facts."""
        extractor, heart, bus, http_client = self._make_extractor()

        existing_fact = MagicMock(spec=FactSummary)
        existing_fact.score = 0.90  # Above 0.85 -> deduped
        heart.search_facts = AsyncMock(return_value=[existing_fact])
        heart.learn = AsyncMock()

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {"summary": "Already known.", "key_points": []},
                "candidate_facts": ["Project uses PostgreSQL"],
            },
        )
        await extractor.handle(event)

        http_client.post.assert_not_called()
        heart.learn.assert_not_called()  # Deduped

    @pytest.mark.asyncio
    async def test_falls_back_to_llm_without_candidate_facts(self):
        """008.4: When no candidate_facts, falls back to LLM extraction."""
        facts_json = [
            {"subject": "user", "content": "User likes tests", "category": "preference", "confidence": 0.9},
        ]
        extractor, heart, bus, http_client = self._make_extractor()
        heart.search_facts = AsyncMock(return_value=[])
        heart.learn = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(facts_json)))
        )

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {"summary": "User likes testing.", "key_points": ["testing"]},
                # No candidate_facts key at all
            },
        )
        await extractor.handle(event)

        # LLM SHOULD be called (fallback)
        http_client.post.assert_called_once()
        heart.learn.assert_called_once()

    @pytest.mark.asyncio
    async def test_candidate_facts_max_5(self):
        """008.4: candidate_facts respects max 5 limit."""
        extractor, heart, bus, http_client = self._make_extractor()
        heart.search_facts = AsyncMock(return_value=[])
        heart.learn = AsyncMock()

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {"summary": "Many facts.", "key_points": []},
                "candidate_facts": [f"Fact number {i}" for i in range(8)],
            },
        )
        await extractor.handle(event)

        http_client.post.assert_not_called()
        assert heart.learn.call_count == 5  # Max 5


# ===========================================================================
# TestTranscriptCapture — 3 tests
# ===========================================================================


class TestTranscriptCapture:
    """Transcript accumulation in SessionMetadata."""

    def test_user_messages_appended_to_transcript(self):
        """21. User messages appended to transcript in pre_turn."""
        meta = SessionMetadata()
        # Simulate what pre_turn does
        meta.transcript.append(f"User: {'Hello world'[:500]}")
        assert len(meta.transcript) == 1
        assert meta.transcript[0] == "User: Hello world"

    def test_assistant_responses_appended_truncated(self):
        """22. Assistant responses appended (truncated to 500 chars) in post_turn."""
        meta = SessionMetadata()
        long_response = "x" * 1000
        # Simulate what post_turn does
        meta.transcript.append(f"Assistant: {long_response[:500]}")
        assert len(meta.transcript) == 1
        assert meta.transcript[0] == f"Assistant: {'x' * 500}"
        assert len(meta.transcript[0]) == 511  # "Assistant: " (11) + 500

    def test_transcript_passed_in_session_ended_event(self):
        """23. Transcript passed in session_ended event data."""
        meta = SessionMetadata()
        meta.transcript.append("User: Hello")
        meta.transcript.append("Assistant: Hi there")
        meta.transcript.append("User: How are you?")

        # Simulate what end_session does
        transcript_text = "\n\n".join(meta.transcript)
        event_data = {
            "episode_id": str(uuid4()),
            "transcript": transcript_text,
            "reflection": None,
        }

        assert "User: Hello" in event_data["transcript"]
        assert "Assistant: Hi there" in event_data["transcript"]
        assert "User: How are you?" in event_data["transcript"]
        assert event_data["transcript"].count("\n\n") == 2


# ===========================================================================
# TestUserTagging — 3 tests
# ===========================================================================


class TestUserTagging:
    """F010.5 user-tagged episodes."""

    def test_episode_input_with_user_id(self):
        """24. Episode created with user_id."""
        episode_input = EpisodeInput(
            summary="Test episode",
            user_id="user-123",
        )
        assert episode_input.user_id == "user-123"

    def test_episode_input_with_user_display_name(self):
        """25. Episode created with user_display_name."""
        episode_input = EpisodeInput(
            summary="Test episode",
            user_display_name="John Doe",
        )
        assert episode_input.user_display_name == "John Doe"

    def test_missing_user_id_defaults_to_none(self):
        """26. Missing user_id defaults to None (backward compat)."""
        episode_input = EpisodeInput(summary="Test episode")
        assert episode_input.user_id is None
        assert episode_input.user_display_name is None


# ===========================================================================
# TestSessionTimeoutMonitor — 7 tests
# ===========================================================================


class TestSessionTimeoutMonitor:
    """Session timeout detection."""

    def _make_monitor(self, settings=None, cognitive=None):
        from nous.handlers.session_monitor import SessionTimeoutMonitor

        bus = EventBus()
        settings = settings or _mock_settings(session_idle_timeout=5, sleep_timeout=10, sleep_check_interval=1)
        cognitive = cognitive or AsyncMock()
        monitor = SessionTimeoutMonitor(bus, settings, cognitive=cognitive)
        return monitor, bus, cognitive

    @pytest.mark.asyncio
    async def test_activity_tracked_on_turn_completed(self):
        """27. Activity tracked on turn_completed."""
        monitor, bus, cognitive = self._make_monitor()

        event = _make_event("turn_completed", session_id="sess-1", agent_id="agent-1")
        await monitor.on_activity(event)

        assert "sess-1" in monitor._last_activity
        assert "sess-1" in monitor._last_agent
        assert monitor._last_agent["sess-1"] == "agent-1"

    @pytest.mark.asyncio
    async def test_session_ended_after_idle_timeout(self):
        """28. session_ended triggered after idle timeout (calls cognitive.end_session, NOT raw event)."""
        monitor, bus, cognitive = self._make_monitor(
            settings=_mock_settings(session_idle_timeout=0, sleep_timeout=9999, sleep_check_interval=1)
        )

        # Record activity
        event = _make_event("turn_completed", session_id="sess-1", agent_id="agent-1")
        await monitor.on_activity(event)

        # Force the last_activity to be in the past
        monitor._last_activity["sess-1"] = time.monotonic() - 10

        await monitor._check_timeouts()

        # Should call cognitive.end_session, not raw bus emit
        cognitive.end_session.assert_called_once()
        call_kwargs = cognitive.end_session.call_args[1]
        assert call_kwargs["agent_id"] == "agent-1"
        assert call_kwargs["session_id"] == "sess-1"

    @pytest.mark.asyncio
    async def test_multiple_sessions_tracked_independently(self):
        """29. Multiple sessions tracked independently."""
        monitor, bus, cognitive = self._make_monitor()

        await monitor.on_activity(_make_event("turn_completed", session_id="sess-1", agent_id="a1"))
        await monitor.on_activity(_make_event("turn_completed", session_id="sess-2", agent_id="a2"))

        assert "sess-1" in monitor._last_activity
        assert "sess-2" in monitor._last_activity
        assert monitor._last_agent["sess-1"] == "a1"
        assert monitor._last_agent["sess-2"] == "a2"

    @pytest.mark.asyncio
    async def test_sleep_started_after_global_idle(self):
        """30. sleep_started emitted after global idle (no active sessions)."""
        monitor, bus, cognitive = self._make_monitor(
            settings=_mock_settings(session_idle_timeout=9999, sleep_timeout=0, sleep_check_interval=1)
        )

        # No active sessions, global idle exceeded
        monitor._global_last_activity = time.monotonic() - 10
        # Make sure no active sessions remain
        monitor._last_activity.clear()

        received: list[Event] = []

        async def capture(event: Event) -> None:
            received.append(event)

        bus.on("sleep_started", capture)
        await bus.start()
        try:
            await monitor._check_timeouts()
            await asyncio.sleep(0.1)
            assert len(received) == 1
            assert received[0].type == "sleep_started"
        finally:
            await bus.stop()

    @pytest.mark.asyncio
    async def test_sleep_not_emitted_while_sessions_active(self):
        """31. sleep_started NOT emitted while sessions still active."""
        monitor, bus, cognitive = self._make_monitor(
            settings=_mock_settings(session_idle_timeout=9999, sleep_timeout=0, sleep_check_interval=1)
        )

        # Active session exists
        monitor._last_activity["sess-1"] = time.monotonic()
        monitor._global_last_activity = time.monotonic() - 100

        received: list[Event] = []

        async def capture(event: Event) -> None:
            received.append(event)

        bus.on("sleep_started", capture)
        await bus.start()
        try:
            await monitor._check_timeouts()
            await asyncio.sleep(0.1)
            assert len(received) == 0
        finally:
            await bus.stop()

    @pytest.mark.asyncio
    async def test_activity_resets_sleep_flag(self):
        """32. Activity resets sleep flag."""
        monitor, bus, cognitive = self._make_monitor()
        monitor._sleep_emitted = True

        await monitor.on_activity(_make_event("turn_completed", session_id="sess-1"))

        assert monitor._sleep_emitted is False

    @pytest.mark.asyncio
    async def test_expired_sessions_cleaned_from_tracking(self):
        """33. Expired sessions cleaned from tracking dict."""
        monitor, bus, cognitive = self._make_monitor(
            settings=_mock_settings(session_idle_timeout=0, sleep_timeout=9999, sleep_check_interval=1)
        )

        # Add session that's already expired
        monitor._last_activity["sess-expired"] = time.monotonic() - 100
        monitor._last_agent["sess-expired"] = "agent-1"

        await monitor._check_timeouts()

        assert "sess-expired" not in monitor._last_activity
        assert "sess-expired" not in monitor._last_agent


# ===========================================================================
# TestSleepHandler — 8 tests
# ===========================================================================


class TestSleepHandler:
    """Sleep mode — reflection, compaction, pruning."""

    def _make_sleep_handler(self, brain=None, heart=None, settings=None, bus=None, http_client=None):
        from nous.handlers.sleep_handler import SleepHandler

        brain = brain or AsyncMock()
        heart = heart or AsyncMock()
        settings = settings or _mock_settings()
        bus = bus or MagicMock(spec=EventBus)
        bus.on = MagicMock()
        bus.emit = AsyncMock()
        http_client = http_client or AsyncMock(spec=httpx.AsyncClient)
        handler = SleepHandler(brain, heart, settings, bus, http_client)
        return handler, brain, heart, bus, http_client

    @pytest.mark.asyncio
    async def test_all_5_phases_run_when_not_interrupted(self):
        """34. All 5 phases run when not interrupted."""
        handler, brain, heart, bus, http_client = self._make_sleep_handler()

        # Mock all phases to be no-ops (stubs in real implementation)
        handler._phase_review_decisions = AsyncMock()
        handler._phase_prune = AsyncMock()
        handler._phase_compress = AsyncMock()
        handler._phase_reflect = AsyncMock()
        handler._phase_generalize = AsyncMock()

        event = _make_event("sleep_started", agent_id="system")
        await handler._run_sleep(event)

        handler._phase_review_decisions.assert_called_once()
        handler._phase_prune.assert_called_once()
        handler._phase_compress.assert_called_once()
        handler._phase_reflect.assert_called_once()
        handler._phase_generalize.assert_called_once()

        # Check sleep_completed emitted
        bus.emit.assert_called_once()
        emitted = bus.emit.call_args[0][0]
        assert emitted.type == "sleep_completed"
        assert len(emitted.data["phases_completed"]) == 5
        assert emitted.data["interrupted"] is False

    @pytest.mark.asyncio
    async def test_message_received_interrupts_sleep(self):
        """35. message_received interrupts sleep (sets _interrupted)."""
        handler, brain, heart, bus, http_client = self._make_sleep_handler()
        handler._sleeping = True

        wake_event = _make_event("message_received")
        await handler._on_wake(wake_event)

        assert handler._interrupted is True

    @pytest.mark.asyncio
    async def test_free_phases_before_llm_phases(self):
        """36. Free phases (review, prune) run before LLM phases."""
        handler, brain, heart, bus, http_client = self._make_sleep_handler()
        order: list[str] = []

        async def track_review():
            order.append("review")

        async def track_prune():
            order.append("prune")

        async def track_compress():
            order.append("compress")

        async def track_reflect():
            order.append("reflect")

        async def track_generalize():
            order.append("generalize")

        handler._phase_review_decisions = track_review
        handler._phase_prune = track_prune
        handler._phase_compress = track_compress
        handler._phase_reflect = track_reflect
        handler._phase_generalize = track_generalize

        await handler._run_sleep(_make_event("sleep_started"))

        assert order == ["review", "prune", "compress", "reflect", "generalize"]
        # Free phases (review, prune) are first two
        assert order[:2] == ["review", "prune"]

    @pytest.mark.asyncio
    async def test_sleep_completed_reports_phases_ran(self):
        """37. sleep_completed reports which phases ran."""
        handler, brain, heart, bus, http_client = self._make_sleep_handler()
        handler._phase_review_decisions = AsyncMock()
        handler._phase_prune = AsyncMock()
        handler._phase_compress = AsyncMock()
        handler._phase_reflect = AsyncMock()
        handler._phase_generalize = AsyncMock()

        await handler._run_sleep(_make_event("sleep_started"))

        emitted = bus.emit.call_args[0][0]
        assert "review" in emitted.data["phases_completed"]
        assert "prune" in emitted.data["phases_completed"]
        assert "compress" in emitted.data["phases_completed"]
        assert "reflect" in emitted.data["phases_completed"]
        assert "generalize" in emitted.data["phases_completed"]

    @pytest.mark.asyncio
    async def test_sleep_completed_reports_interrupted(self):
        """38. sleep_completed reports interrupted=True when interrupted."""
        handler, brain, heart, bus, http_client = self._make_sleep_handler()

        async def interrupt_during_compress():
            handler._interrupted = True

        handler._phase_review_decisions = AsyncMock()
        handler._phase_prune = AsyncMock()
        handler._phase_compress = interrupt_during_compress
        handler._phase_reflect = AsyncMock()
        handler._phase_generalize = AsyncMock()

        await handler._run_sleep(_make_event("sleep_started"))

        emitted = bus.emit.call_args[0][0]
        # review + prune + compress ran, then interrupted before reflect/generalize
        assert "review" in emitted.data["phases_completed"]
        assert "prune" in emitted.data["phases_completed"]
        assert "compress" in emitted.data["phases_completed"]
        assert "reflect" not in emitted.data["phases_completed"]
        assert "generalize" not in emitted.data["phases_completed"]
        assert emitted.data["interrupted"] is True

    @pytest.mark.asyncio
    async def test_reflection_generates_facts(self):
        """39. Reflection generates facts from cross-session patterns (mock LLM)."""
        handler, brain, heart, bus, http_client = self._make_sleep_handler()

        # Mock list_episodes returning >= 2 episodes
        ep1 = MagicMock()
        ep1.summary = "Discussed Python testing patterns"
        ep2 = MagicMock()
        ep2.summary = "Worked on Python async code"
        heart.list_episodes = AsyncMock(return_value=[ep1, ep2])
        heart.learn = AsyncMock()

        reflection_json = {
            "patterns": ["User works with Python frequently"],
            "lessons": ["Always write tests first"],
            "connections": [],
            "gaps": [],
            "summary": "The agent primarily assists with Python development.",
        }
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(reflection_json)))
        )

        await handler._phase_reflect()

        # Should store reflection summary + lessons as facts
        assert heart.learn.call_count >= 1
        # Check that at least one fact was stored with source="sleep_reflection"
        any_sleep_fact = any(
            call[0][0].source == "sleep_reflection" for call in heart.learn.call_args_list
        )
        assert any_sleep_fact

    @pytest.mark.asyncio
    async def test_reflection_skipped_when_few_episodes(self):
        """40. Reflection skipped when <2 recent episodes."""
        handler, brain, heart, bus, http_client = self._make_sleep_handler()

        # Only 1 episode
        ep1 = MagicMock()
        ep1.summary = "Single episode"
        heart.list_episodes = AsyncMock(return_value=[ep1])
        heart.learn = AsyncMock()

        await handler._phase_reflect()

        heart.learn.assert_not_called()
        http_client.post.assert_not_called()

    @pytest.mark.asyncio
    async def test_llm_failure_doesnt_crash_sleep(self):
        """41. LLM failure doesn't crash sleep handler."""
        handler, brain, heart, bus, http_client = self._make_sleep_handler()

        # Make all phases pass except reflect which has LLM failure
        handler._phase_review_decisions = AsyncMock()
        handler._phase_prune = AsyncMock()
        handler._phase_compress = AsyncMock()
        handler._phase_generalize = AsyncMock()

        # Set up reflect to fail via LLM
        ep1 = MagicMock()
        ep1.summary = "Episode 1"
        ep2 = MagicMock()
        ep2.summary = "Episode 2"
        heart.search_episodes = AsyncMock(return_value=[ep1, ep2])
        http_client.post = AsyncMock(side_effect=httpx.TimeoutException("timeout"))

        # _run_sleep should not raise
        await handler._run_sleep(_make_event("sleep_started"))

        # sleep_completed should still be emitted
        bus.emit.assert_called_once()
        emitted = bus.emit.call_args[0][0]
        assert emitted.type == "sleep_completed"


# ===========================================================================
# TestReviewFixes — 4 additional tests
# ===========================================================================


class TestReviewFixes:
    """Additional review-fix tests."""

    @pytest.mark.asyncio
    async def test_bus_none_backward_compat(self):
        """42. bus=None backward compat -- events still go to Brain.emit_event."""
        from nous.cognitive.layer import CognitiveLayer
        from nous.cognitive.schemas import TurnContext, TurnResult
        from nous.cognitive.schemas import FrameSelection

        brain = AsyncMock()
        brain.db = MagicMock()
        brain.embeddings = AsyncMock()
        brain.embeddings.embed = AsyncMock(return_value=[0.1] * 1536)
        heart = AsyncMock()
        heart.start_episode = AsyncMock()
        heart.focus = AsyncMock()
        heart.get_or_create_working_memory = AsyncMock()
        heart.list_censors = AsyncMock(return_value=[])
        settings = _mock_settings()

        # Create CognitiveLayer WITHOUT bus (bus=None)
        cognitive = CognitiveLayer(brain, heart, settings, "")

        # Mock the sub-engines to avoid DB calls
        cognitive._frames = MagicMock()
        cognitive._frames.select = AsyncMock(return_value=FrameSelection(
            frame_id="conversation", frame_name="Conversation",
            confidence=0.9, match_method="default",
        ))
        cognitive._frames._default_selection = MagicMock()
        cognitive._context = MagicMock()
        cognitive._context.build = AsyncMock(return_value=MagicMock(
            system_prompt="prompt", sections=[], recalled_ids={}, recalled_content_map={},
        ))
        cognitive._context._identity_prompt = ""
        cognitive._deliberation = MagicMock()
        cognitive._deliberation.should_deliberate = AsyncMock(return_value=False)
        cognitive._monitor = MagicMock()
        cognitive._monitor.assess = AsyncMock(return_value=MagicMock(
            surprise_level=0.0, decision_id=None, intended=None,
            actual="test", censor_candidates=[], facts_extracted=0, episode_recorded=False,
        ))
        cognitive._monitor.learn = AsyncMock(return_value=MagicMock(
            surprise_level=0.0, decision_id=None, intended=None,
            actual="test", censor_candidates=[], facts_extracted=0, episode_recorded=False,
        ))
        cognitive._monitor._session_censor_counts = {}

        # Do a turn
        turn_context = await cognitive.pre_turn("agent-1", "sess-1", "hello")
        turn_result = TurnResult(response_text="Hi there")
        await cognitive.post_turn("agent-1", "sess-1", turn_result, turn_context)

        # Without bus, should fall back to brain.emit_event
        brain.emit_event.assert_called()
        # Should have been called with "turn_completed"
        call_args = brain.emit_event.call_args_list[-1]
        assert call_args[0][0] == "turn_completed"

    @pytest.mark.asyncio
    async def test_sleep_handler_spawns_task_returns_immediately(self):
        """43. Sleep handler spawns task and returns immediately (bus not blocked)."""
        from nous.handlers.sleep_handler import SleepHandler

        brain = AsyncMock()
        heart = AsyncMock()
        settings = _mock_settings()
        bus = MagicMock(spec=EventBus)
        bus.on = MagicMock()
        bus.emit = AsyncMock()

        handler = SleepHandler(brain, heart, settings, bus)

        # Make _run_sleep take some time
        original_run_sleep = handler._run_sleep
        run_sleep_started = asyncio.Event()
        run_sleep_finished = asyncio.Event()

        async def slow_run_sleep(event):
            run_sleep_started.set()
            await asyncio.sleep(0.2)
            run_sleep_finished.set()

        handler._run_sleep = slow_run_sleep

        event = _make_event("sleep_started")
        # handle() should return immediately (spawns task)
        await handler.handle(event)

        # _run_sleep should have started but not finished
        await asyncio.sleep(0.05)
        assert run_sleep_started.is_set()
        assert not run_sleep_finished.is_set()

        # Wait for completion
        await asyncio.sleep(0.3)
        assert run_sleep_finished.is_set()

    @pytest.mark.asyncio
    async def test_session_monitor_calls_cognitive_end_session(self):
        """44. Session monitor calls cognitive.end_session (not raw session_ended)."""
        from nous.handlers.session_monitor import SessionTimeoutMonitor

        bus = EventBus()
        settings = _mock_settings(session_idle_timeout=0, sleep_timeout=9999, sleep_check_interval=1)
        cognitive = AsyncMock()

        monitor = SessionTimeoutMonitor(bus, settings, cognitive=cognitive)

        # Simulate activity in the past
        monitor._last_activity["sess-timeout"] = time.monotonic() - 100
        monitor._last_agent["sess-timeout"] = "agent-1"

        await monitor._check_timeouts()

        cognitive.end_session.assert_called_once_with(
            agent_id="agent-1",
            session_id="sess-timeout",
            reflection=None,
        )

    @pytest.mark.asyncio
    async def test_fact_extractor_passes_category(self):
        """45. FactExtractor passes category to FactInput."""
        from nous.handlers.fact_extractor import FactExtractor

        heart = AsyncMock()
        settings = _mock_settings()
        bus = MagicMock(spec=EventBus)
        bus.on = MagicMock()
        bus.emit = AsyncMock()
        http_client = AsyncMock(spec=httpx.AsyncClient)

        extractor = FactExtractor(heart, settings, bus, http_client)

        facts_json = [
            {
                "subject": "project",
                "content": "Uses PostgreSQL",
                "category": "technical",
                "confidence": 0.95,
            },
        ]
        heart.search_facts = AsyncMock(return_value=[])
        heart.learn = AsyncMock()
        http_client.post = AsyncMock(
            return_value=_mock_httpx_response(200, _llm_response(json.dumps(facts_json)))
        )

        event = _make_event(
            "episode_summarized",
            data={
                "episode_id": str(uuid4()),
                "summary": {"summary": "Project uses PostgreSQL.", "key_points": ["postgres"]},
            },
        )
        await extractor.handle(event)

        heart.learn.assert_called_once()
        fact_input = heart.learn.call_args[0][0]
        assert fact_input.category == "technical"
