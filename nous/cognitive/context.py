"""Context assembly engine — builds system prompt within token budgets.

Queries Brain and Heart, formats results as markdown sections,
and concatenates them in priority order within per-section token budgets.
"""

from __future__ import annotations

import logging
from uuid import UUID

from sqlalchemy.ext.asyncio import AsyncSession

from nous.utils import text_overlap

from nous.brain.brain import Brain
from nous.cognitive.dedup import ConversationDeduplicator
from nous.cognitive.intent import RetrievalPlan
from nous.cognitive.schemas import BuildResult, ContextBudget, ContextSection, FrameSelection
from nous.cognitive.usage_tracker import UsageTracker
from nous.config import Settings
from nous.heart.heart import Heart
from nous.heart.search import apply_frame_boost

logger = logging.getLogger(__name__)


class ContextEngine:
    """Assembles context from Brain and Heart within token budgets."""

    CHARS_PER_TOKEN = 4

    def __init__(
        self,
        brain: Brain,
        heart: Heart,
        settings: Settings,
        identity_prompt: str = "",
        deduplicator: ConversationDeduplicator | None = None,
    ) -> None:
        self._brain = brain
        self._heart = heart
        self._settings = settings
        self._identity_prompt = identity_prompt
        self._deduplicator = deduplicator

    async def build(
        self,
        agent_id: str,
        session_id: str,
        input_text: str,
        frame: FrameSelection,
        session: AsyncSession | None = None,
        *,
        conversation_messages: list[str] | None = None,
        retrieval_plan: RetrievalPlan | None = None,
        usage_tracker: UsageTracker | None = None,
        identity_override: str | None = None,
    ) -> BuildResult:
        """Build system prompt + context sections within budget.

        Returns BuildResult with system_prompt, sections, recalled_ids,
        and recalled_content_map.

        New optional parameters (all backward-compatible):
        - conversation_messages: Recent messages for deduplication (D4).
        - retrieval_plan: Intent-driven retrieval plan (D2). Falls back to default.
        - usage_tracker: Feedback tracker for boost/penalty (D3).

        Assembly order (by priority):
        1. Identity prompt (always included, static)
        2. Active censors (always, action=block first)
        3. Frame description + questions_to_ask
        4. Working memory (current task + open threads)
        5. Similar decisions from Brain.query()
        6. Relevant facts from Heart.search_facts()
        7. Relevant procedures from Heart.search_procedures()
        8. Related episodes from Heart.search_episodes()

        Pipeline order per memory type (F10):
        retrieve -> apply_frame_boost -> dedup -> usage_boost -> truncate
        """
        budget = ContextBudget.for_frame(frame.frame_id)
        sections: list[ContextSection] = []
        _active_censor_names: list[str] = []
        recalled_ids: dict[str, list[str]] = {
            "decision": [],
            "fact": [],
            "procedure": [],
            "episode": [],
        }
        recalled_content_map: dict[str, str] = {}

        # Apply budget overrides from retrieval plan (F6: REPLACE semantics)
        skip_types: set[str] = set()
        if retrieval_plan:
            if retrieval_plan.budget_overrides:
                budget.apply_overrides(retrieval_plan.budget_overrides)
            skip_types = retrieval_plan.skip_types

        # Determine per-type query text and limits from plan
        _query_texts: dict[str, str] = {}
        _limits: dict[str, int] = {}
        if retrieval_plan and retrieval_plan.queries:
            for q in retrieval_plan.queries:
                _limits[q.memory_type] = q.limit
                if q.query_text:
                    _query_texts[q.memory_type] = q.query_text

        # Trim conversation_messages to budget.conversation_window (F13)
        _conv_msgs = conversation_messages
        if _conv_msgs:
            _conv_msgs = _conv_msgs[-budget.conversation_window :]

        # 1. Identity (always included)
        # 008: Use identity_override from DB if available, fall back to static
        _effective_identity = identity_override or self._identity_prompt
        if _effective_identity:
            identity_text = self._truncate_to_budget(_effective_identity, budget.identity)
            sections.append(
                ContextSection(
                    priority=1,
                    label="Identity",
                    content=identity_text,
                    token_estimate=self._estimate_tokens(identity_text),
                )
            )

        # 2. Censors (P2-5: per-section isolation)
        if budget.censors > 0:
            try:
                censors = await self._heart.list_censors(session=session)
                if censors:
                    _active_censor_names = [str(getattr(c, "id", "")) for c in censors]
                    censor_text = self._format_censors(censors)
                    censor_text = self._truncate_to_budget(censor_text, budget.censors)
                    sections.append(
                        ContextSection(
                            priority=2,
                            label="Active Censors",
                            content=censor_text,
                            token_estimate=self._estimate_tokens(censor_text),
                        )
                    )
            except Exception:
                logger.warning("Failed to load censors during context build")

        # 3. Frame
        if budget.frame > 0:
            frame_text = self._format_frame(frame)
            frame_text = self._truncate_to_budget(frame_text, budget.frame)
            sections.append(
                ContextSection(
                    priority=3,
                    label="Current Frame",
                    content=frame_text,
                    token_estimate=self._estimate_tokens(frame_text),
                )
            )

        # 4. Working memory (P1-7: no agent_id param)
        # Hoisted: fetch wm early so current_topic is available for query enhancement (007.2)
        wm = None
        current_topic: str | None = None
        try:
            wm = await self._heart.get_working_memory(session_id, session=session)
        except Exception:
            logger.warning("Failed to load working memory during context build")

        if wm is not None:
            current_topic = getattr(wm, "current_task", None)

        if budget.working_memory > 0 and wm is not None:
            wm_text = self._format_working_memory(wm)
            wm_text = self._truncate_to_budget(wm_text, budget.working_memory)
            sections.append(
                ContextSection(
                    priority=4,
                    label="Working Memory",
                    content=wm_text,
                    token_estimate=self._estimate_tokens(wm_text),
                )
            )

        # 007.2: Topic-enhanced default query — prefix with current_topic
        _default_query = f"{current_topic}: {input_text}" if current_topic else input_text

        # 5. Decisions (F26: skip_types is primary skip mechanism)
        if budget.decisions > 0 and "decision" not in skip_types:
            try:
                limit = _limits.get("decision", 5)
                q_text = _query_texts.get("decision", _default_query)
                decisions = await self._brain.query(q_text, limit=limit, session=session)
                if decisions:
                    # 007.2: Diversity filter — use category as topic key
                    decisions = self._enforce_diversity(decisions, "category", max_per_subject=3)
                    # F1: Collect recalled IDs
                    for d in decisions:
                        mid = str(getattr(d, "id", ""))
                        if mid:
                            recalled_ids["decision"].append(mid)
                    # Format content for each decision (F8: recalled_content_map)
                    dec_text = self._format_decisions(decisions)
                    for d in decisions:
                        mid = str(getattr(d, "id", ""))
                        if mid:
                            desc = getattr(d, "description", "")
                            recalled_content_map[mid] = desc
                    dec_text = self._truncate_to_budget(dec_text, budget.decisions)
                    sections.append(
                        ContextSection(
                            priority=5,
                            label="Related Decisions",
                            content=dec_text,
                            token_estimate=self._estimate_tokens(dec_text),
                        )
                    )
            except Exception:
                logger.warning("Brain.query failed during context build")

        # 6. Facts (F10: retrieve -> apply_frame_boost -> dedup -> usage_boost -> truncate)
        if budget.facts > 0 and "fact" not in skip_types:
            try:
                limit = _limits.get("fact", 5)
                q_text = _query_texts.get("fact", _default_query)
                facts = await self._heart.search_facts(q_text, limit=limit, session=session)
                if facts:
                    # F10: apply_frame_boost (preserved from existing pipeline)
                    facts = apply_frame_boost(facts, frame.frame_id, _active_censor_names)

                    # 007.2: Diversity filter — use subject as topic key
                    facts = self._enforce_diversity(facts, "subject", max_per_subject=2)

                    # Dedup against conversation
                    facts = await self._apply_dedup(facts, _conv_msgs, "content")

                    # Usage boost
                    facts = self._apply_usage_boost(facts, usage_tracker)

                    # F1: Collect recalled IDs AFTER filtering (P1-1 fix:
                    # collecting before dedup would penalize deduped memories
                    # in the usage tracker as "retrieved but not referenced")
                    for f in facts:
                        mid = str(getattr(f, "id", ""))
                        if mid:
                            recalled_ids["fact"].append(mid)
                            recalled_content_map[mid] = getattr(f, "content", "")

                    facts_text = self._format_facts(facts)
                    facts_text = self._truncate_to_budget(facts_text, budget.facts)
                    sections.append(
                        ContextSection(
                            priority=6,
                            label="Relevant Facts",
                            content=facts_text,
                            token_estimate=self._estimate_tokens(facts_text),
                        )
                    )
            except Exception:
                logger.warning("Heart.search_facts failed during context build")

        # 7. Procedures
        if budget.procedures > 0 and "procedure" not in skip_types:
            try:
                limit = _limits.get("procedure", 5)
                q_text = _query_texts.get("procedure", _default_query)
                procedures = await self._heart.search_procedures(q_text, limit=limit, session=session)
                if procedures:
                    # F10: apply_frame_boost
                    procedures = apply_frame_boost(procedures, frame.frame_id, _active_censor_names)

                    # Dedup + usage boost
                    procedures = await self._apply_dedup(procedures, _conv_msgs, "name")
                    procedures = self._apply_usage_boost(procedures, usage_tracker)

                    # F1: Collect recalled IDs AFTER filtering (P1-1 fix)
                    for p in procedures:
                        mid = str(getattr(p, "id", ""))
                        if mid:
                            recalled_ids["procedure"].append(mid)
                            recalled_content_map[mid] = getattr(p, "name", "")

                    proc_text = self._format_procedures(procedures)
                    proc_text = self._truncate_to_budget(proc_text, budget.procedures)
                    sections.append(
                        ContextSection(
                            priority=7,
                            label="Known Procedures",
                            content=proc_text,
                            token_estimate=self._estimate_tokens(proc_text),
                        )
                    )
            except Exception:
                logger.warning("Heart.search_procedures failed during context build")

        # 8. Episodes
        if budget.episodes > 0 and "episode" not in skip_types:
            try:
                limit = _limits.get("episode", 5)
                q_text = _query_texts.get("episode", _default_query)
                episodes = await self._heart.search_episodes(q_text, limit=limit, session=session)
                if episodes:
                    # F10: apply_frame_boost
                    episodes = apply_frame_boost(episodes, frame.frame_id, _active_censor_names)

                    # 007.2: Diversity filter — use first tag as topic key
                    episodes = self._enforce_diversity(episodes, "tags", max_per_subject=2)

                    # Dedup + usage boost
                    episodes = await self._apply_dedup(episodes, _conv_msgs, "summary")
                    episodes = self._apply_usage_boost(episodes, usage_tracker)

                    # F1: Collect recalled IDs AFTER filtering (P1-1 fix)
                    for e in episodes:
                        mid = str(getattr(e, "id", ""))
                        if mid:
                            recalled_ids["episode"].append(mid)
                            recalled_content_map[mid] = getattr(e, "summary", "")

                    ep_text = self._format_episodes(episodes)
                    ep_text = self._truncate_to_budget(ep_text, budget.episodes)
                    sections.append(
                        ContextSection(
                            priority=8,
                            label="Past Episodes",
                            content=ep_text,
                            token_estimate=self._estimate_tokens(ep_text),
                        )
                    )
            except Exception:
                logger.warning("Heart.search_episodes failed during context build")

        # Assemble system prompt with markdown headers
        parts: list[str] = []
        for section in sorted(sections, key=lambda s: s.priority):
            parts.append(f"## {section.label}\n\n{section.content}")

        system_prompt = "\n\n".join(parts)
        return BuildResult(
            system_prompt=system_prompt,
            sections=sections,
            recalled_ids=recalled_ids,
            recalled_content_map=recalled_content_map,
        )

    async def _apply_dedup(
        self,
        items: list,
        conversation_messages: list[str] | None,
        content_attr: str,
    ) -> list:
        """Apply conversation deduplication to retrieved items.

        Filters out items whose content is redundant with recent conversation.
        """
        if not self._deduplicator or not conversation_messages or not items:
            return items

        try:
            memories = [
                (str(getattr(item, "id", "")), getattr(item, content_attr, ""))
                for item in items
            ]
            results = await self._deduplicator.check(memories, conversation_messages)
            # Filter out redundant items
            redundant_ids = {r.memory_id for r in results if r.is_redundant}
            return [
                item for item in items if str(getattr(item, "id", "")) not in redundant_ids
            ]
        except Exception:
            logger.warning("Dedup failed, keeping all items")
            return items

    def _apply_usage_boost(self, items: list, usage_tracker: UsageTracker | None) -> list:
        """Re-rank items using usage-based boost factors.

        Items with high reference rates get boosted; items retrieved
        but rarely referenced get penalized.
        """
        if not usage_tracker or not items:
            return items

        boosted = []
        for item in items:
            mid = str(getattr(item, "id", ""))
            boost = usage_tracker.get_boost_factor(mid) if mid else 1.0
            boosted.append((item, boost))

        boosted.sort(key=lambda x: x[1], reverse=True)
        return [item for item, _ in boosted]

    def _enforce_diversity(self, items: list, topic_attr: str, max_per_subject: int = 2) -> list:
        """Prevent one topic from dominating recall results (007.2).

        Extracts a topic key from each item using topic_attr:
        - String attrs (e.g. 'subject', 'category'): first word, lowercased
        - List attrs (e.g. 'tags'): first element, lowercased
        Items without the attr default to 'unknown'.
        """
        if not items:
            return items

        seen: dict[str, int] = {}
        result = []
        for item in items:
            raw = getattr(item, topic_attr, None)
            if isinstance(raw, list):
                topic_key = raw[0].lower() if raw else "unknown"
            elif isinstance(raw, str) and raw:
                topic_key = raw.split()[0].lower()
            else:
                topic_key = "unknown"

            count = seen.get(topic_key, 0)
            if count < max_per_subject:
                result.append(item)
                seen[topic_key] = count + 1
        return result

    def _estimate_tokens(self, text: str) -> int:
        """Rough token count: len(text) / CHARS_PER_TOKEN."""
        return max(1, len(text) // self.CHARS_PER_TOKEN)

    def _truncate_to_budget(self, text: str, token_budget: int) -> str:
        """Truncate text to fit within token budget."""
        max_chars = token_budget * self.CHARS_PER_TOKEN
        if len(text) <= max_chars:
            return text
        return text[: max_chars - 3] + "..."

    def _format_decisions(self, decisions: list) -> str:
        """Format decision summaries for context.

        P1-10: No reasons field on DecisionSummary.
        Format: - [{outcome}] {description} (confidence: {confidence})
        """
        lines = []
        for d in decisions:
            outcome = getattr(d, "outcome", "pending") or "pending"
            desc = getattr(d, "description", "")
            conf = getattr(d, "confidence", 0.0)
            lines.append(f"- [{outcome}] {desc} (confidence: {conf:.2f})")
        return "\n".join(lines)

    def _format_facts(self, facts: list) -> str:
        """Format facts for context.

        Format: - [subject]: content_truncated [confidence: N.NN]
        Truncates content to 200 chars at word boundary.
        """
        lines = []
        for f in facts:
            content = getattr(f, "content", "")
            conf = getattr(f, "confidence", 1.0)
            subject = getattr(f, "subject", None)

            # Truncate at word boundary
            max_len = 200
            if len(content) > max_len:
                truncated = content[:max_len].rsplit(" ", 1)[0]
                content = truncated + "..."

            if subject:
                lines.append(f"- [{subject}] {content} [confidence: {conf:.2f}]")
            else:
                lines.append(f"- {content} [confidence: {conf:.2f}]")
        return "\n".join(lines)

    def _format_procedures(self, procedures: list) -> str:
        """Format procedures for context.

        P2-8: Use name + domain + description (not core_patterns).
        ProcedureSummary has: name, domain, activation_count, effectiveness.
        Format: - **{name}** ({domain}): activated {count}x
        """
        lines = []
        for p in procedures:
            name = getattr(p, "name", "")
            domain = getattr(p, "domain", None) or "general"
            count = getattr(p, "activation_count", 0)
            eff = getattr(p, "effectiveness", None)
            eff_str = f", effectiveness: {eff:.0%}" if eff is not None else ""
            lines.append(f"- **{name}** ({domain}): activated {count}x{eff_str}")
        return "\n".join(lines)

    def _format_episodes(self, episodes: list) -> str:
        """Format episodes for context.

        Format: - [{outcome}] {summary} ({started_at date})
        """
        lines = []
        for e in episodes:
            outcome = getattr(e, "outcome", None) or "ongoing"
            if outcome == "abandoned":
                continue
            summary = getattr(e, "summary", "")
            started = getattr(e, "started_at", None)
            date_str = started.strftime("%Y-%m-%d") if started else "unknown"
            lines.append(f"- [{outcome}] {summary} ({date_str})")
        return "\n".join(lines)

    def _format_censors(self, censors: list) -> str:
        """Format active censors.

        P1-4: Use action (not severity).
        Format: - **{ACTION}:** {trigger_pattern} -- {reason}
        """
        # Sort by action severity: block/absolute first, warn last
        action_order = {"absolute": 0, "block": 1, "warn": 2}
        sorted_censors = sorted(
            censors,
            key=lambda c: action_order.get(getattr(c, "action", "warn"), 3),
        )
        lines = []
        for c in sorted_censors:
            action = getattr(c, "action", "warn").upper()
            pattern = getattr(c, "trigger_pattern", "")
            reason = getattr(c, "reason", "")
            lines.append(f"- **{action}:** {pattern} -- {reason}")
        return "\n".join(lines)

    def _format_frame(self, frame: FrameSelection) -> str:
        """Format frame description and questions."""
        parts = [f"**{frame.frame_name}**: {frame.description or ''}"]
        if frame.questions_to_ask:
            parts.append("\nConsider asking:")
            for q in frame.questions_to_ask:
                parts.append(f"- {q}")
        return "\n".join(parts)

    def _format_working_memory(self, wm) -> str:
        """Format working memory state.

        Includes current_task, open_threads, and high-relevance items.
        """
        parts = []
        task = getattr(wm, "current_task", None)
        if task:
            parts.append(f"**Current task:** {task}")

        frame = getattr(wm, "current_frame", None)
        if frame:
            parts.append(f"**Frame:** {frame}")

        threads = getattr(wm, "open_threads", [])
        if threads:
            parts.append("\n**Open threads:**")
            for t in threads:
                desc = getattr(t, "description", "")
                priority = getattr(t, "priority", "medium")
                parts.append(f"- [{priority}] {desc}")

        items = getattr(wm, "items", [])
        # Only include high-relevance items (>= 0.7)
        high_rel = [i for i in items if getattr(i, "relevance", 0) >= 0.7]
        if high_rel:
            parts.append("\n**Loaded context:**")
            for item in high_rel:
                summary = getattr(item, "summary", "")
                rel = getattr(item, "relevance", 0)
                parts.append(f"- {summary} (relevance: {rel:.1f})")

        return "\n".join(parts) if parts else "No active working memory."

    async def refresh_needed(
        self,
        agent_id: str,
        session_id: str,
        new_input: str,
        current_frame: FrameSelection,
        session: AsyncSession | None = None,
    ) -> bool:
        """Check if context should be rebuilt.

        Returns True if:
        1. Working memory's current_frame differs from current_frame.frame_id
        2. No working memory exists for this session
        """
        try:
            wm = await self._heart.get_working_memory(session_id, session=session)
            if wm is None:
                return True
            return wm.current_frame != current_frame.frame_id
        except Exception:
            return True

    async def expand(
        self,
        memory_type: str,
        memory_id: str,
        session: AsyncSession | None = None,
    ) -> str:
        """Load full detail for a specific memory.

        memory_type: "decision", "fact", "episode", "procedure"
        Routes to Brain.get() or Heart managers accordingly.
        """
        uid = UUID(memory_id)

        if memory_type == "decision":
            detail = await self._brain.get(uid, session=session)
            if detail is None:
                return f"Decision {memory_id} not found."
            return (
                f"**{detail.description}**\n"
                f"Category: {detail.category} | Stakes: {detail.stakes} | "
                f"Confidence: {detail.confidence:.2f}\n"
                f"Context: {detail.context or 'None'}\n"
                f"Pattern: {detail.pattern or 'None'}"
            )

        if memory_type == "fact":
            detail = await self._heart.get_fact(uid, session=session)
            return (
                f"**{detail.content}**\n"
                f"Category: {detail.category or 'None'} | "
                f"Confidence: {detail.confidence:.2f} | "
                f"Source: {detail.source or 'unknown'}"
            )

        if memory_type == "episode":
            detail = await self._heart.get_episode(uid, session=session)
            return (
                f"**{detail.summary}**\n"
                f"Outcome: {detail.outcome or 'ongoing'} | "
                f"Started: {detail.started_at.strftime('%Y-%m-%d %H:%M')}\n"
                f"Lessons: {', '.join(detail.lessons_learned) if detail.lessons_learned else 'None'}"
            )

        if memory_type == "procedure":
            detail = await self._heart.get_procedure(uid, session=session)
            return (
                f"**{detail.name}** ({detail.domain or 'general'})\n"
                f"{detail.description or ''}\n"
                f"Effectiveness: {detail.effectiveness or 'unknown'}"
            )

        return f"Unknown memory type: {memory_type}"

    def _dedup_decisions(self, decisions: list) -> list:
        """Remove near-duplicate decisions, keeping the most recent (006.2).

        Preserves decisions with different outcomes even if descriptions overlap
        (e.g., success and failure on the same task are both valuable).
        """
        if len(decisions) <= 1:
            return decisions

        # Sort newest first so first-seen = most recent
        decisions = sorted(
            decisions,
            key=lambda d: getattr(d, "created_at", None) or "",
            reverse=True,
        )

        kept: list = []
        for d in decisions:
            desc = getattr(d, "description", "") or ""
            outcome = getattr(d, "outcome", "pending") or "pending"
            is_dup = False
            for k in kept:
                k_desc = getattr(k, "description", "") or ""
                k_outcome = getattr(k, "outcome", "pending") or "pending"
                # Only dedup if BOTH description similar AND same outcome
                if (outcome == k_outcome and
                        text_overlap(desc[:150], k_desc[:150]) > 0.80):
                    is_dup = True
                    break
            if not is_dup:
                kept.append(d)
        return kept
