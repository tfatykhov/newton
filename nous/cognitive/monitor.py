"""Monitor engine â€” post-turn self-assessment and learning.

After each turn:
1. Assess: Was the outcome surprising? Did censors fire?
2. Learn: Extract facts, record episode, create censors from failures.
"""

from __future__ import annotations

import logging
from uuid import UUID

from sqlalchemy.ext.asyncio import AsyncSession

from nous.brain.brain import Brain
from nous.cognitive.schemas import Assessment, FrameSelection, ToolResult, TurnResult
from nous.config import Settings
from nous.heart.heart import Heart
from nous.heart.schemas import CensorInput

logger = logging.getLogger(__name__)

# Patterns that indicate transient errors (shouldn't create censors)
_TRANSIENT_PATTERNS = [
    "timeout",
    "rate limit",
    "rate_limit",
    "429",
    "503",
    "connection refused",
    "network error",
    "econnreset",
    "etimedout",
]

# Max auto-created censors per session (P2-4 circuit breaker)
_MAX_CENSORS_PER_SESSION = 3


class MonitorEngine:
    """Post-turn self-assessment and learning.

    After each turn:
    1. Assess: Was the outcome surprising? Did censors fire?
    2. Learn: Extract facts, record episode, create censors from failures.
    """

    def __init__(self, brain: Brain, heart: Heart, settings: Settings) -> None:
        self._brain = brain
        self._heart = heart
        self._settings = settings
        # P2-4: Track censors created per session to enforce cap
        self._session_censor_counts: dict[str, int] = {}

    async def assess(
        self,
        agent_id: str,
        session_id: str,
        turn_result: TurnResult,
        decision_id: str | None = None,
        session: AsyncSession | None = None,
    ) -> Assessment:
        """Evaluate what happened during the turn.

        Steps:
        1. If decision_id exists, fetch the decision from Brain
        2. Calculate surprise_level (P2-3: structural checks only):
           - 0.9 if turn_result.error is not None (turn-level error)
           - 0.3 if any tool_result.error exists
           - 0.0 otherwise
        3. Generate censor_candidates from non-transient tool errors
        4. Return Assessment
        """
        intended = None
        if decision_id:
            try:
                detail = await self._brain.get(UUID(decision_id), session=session)
                if detail:
                    intended = detail.description
            except Exception:
                logger.warning("Failed to fetch decision %s for assessment", decision_id)

        # P2-3: Structural surprise only -- no text matching
        surprise_level = 0.0
        if turn_result.error is not None:
            surprise_level = 0.9
        elif any(tr.error for tr in turn_result.tool_results):
            surprise_level = 0.3

        # Generate censor candidates from non-transient tool errors
        censor_candidates: list[str] = []
        for tr in turn_result.tool_results:
            if tr.error and not self._is_transient_error(tr.error):
                censor_candidates.append(self._error_to_censor_text(tr))

        return Assessment(
            decision_id=decision_id,
            intended=intended,
            actual=turn_result.response_text[:200],
            surprise_level=surprise_level,
            censor_candidates=censor_candidates,
        )

    async def learn(
        self,
        agent_id: str,
        session_id: str,
        assessment: Assessment,
        turn_result: TurnResult,
        frame: FrameSelection,
        episode_id: str | None = None,
        session: AsyncSession | None = None,
    ) -> Assessment:
        """Post-assessment learning -- update state and create artifacts.

        Steps:
        1. If surprise_level > 0.7 and censor_candidates exist:
           - Create censors via Heart.add_censor() for each candidate
           - P2-4: Deduplicate by trigger_pattern, cap at 3 per session
           - P1-5: Construct CensorInput pydantic model
           - P1-4: Use action="warn" (not severity)

        2. If decision_id exists and turn_result has no errors:
           - Record thought "Turn completed successfully" via Brain.think()

        3. P2-2: Do NOT end episode here -- only end in end_session()

        4. Update Assessment with facts_extracted count and episode_recorded flag.

        Returns updated Assessment.
        """
        facts_extracted = 0

        # 1. Create censors from high-surprise tool errors
        if assessment.surprise_level > 0.7 and assessment.censor_candidates:
            session_count = self._session_censor_counts.get(session_id, 0)

            # P2-4: Get existing censors for deduplication
            existing_patterns: set[str] = set()
            try:
                existing = await self._heart.list_censors(session=session)
                existing_patterns = {c.trigger_pattern for c in existing}
            except Exception:
                logger.warning("Failed to load existing censors for dedup check")

            for candidate_text in assessment.censor_candidates:
                # P2-4: Cap at max censors per session
                if session_count >= _MAX_CENSORS_PER_SESSION:
                    break

                # P2-4: Skip if censor with same trigger already exists
                if candidate_text in existing_patterns:
                    continue

                try:
                    # P1-5: Construct CensorInput pydantic model
                    # P1-4: Use action, not severity
                    censor_input = CensorInput(
                        trigger_pattern=candidate_text,
                        reason="Auto-created from tool error",
                        action="warn",
                    )
                    await self._heart.add_censor(censor_input, session=session)
                    existing_patterns.add(candidate_text)
                    session_count += 1
                except Exception:
                    logger.warning("Failed to create censor for: %s", candidate_text[:50])

            self._session_censor_counts[session_id] = session_count

        # 2. Record success thought if deliberation active and no errors
        if assessment.decision_id and turn_result.error is None:
            has_tool_errors = any(tr.error for tr in turn_result.tool_results)
            if not has_tool_errors:
                try:
                    await self._brain.think(
                        UUID(assessment.decision_id),
                        "Turn completed successfully",
                        session=session,
                    )
                except Exception:
                    logger.warning("Failed to record success thought")

        # 3. P2-2: Do NOT end episode here -- only end in end_session()

        # 4. Update assessment
        assessment.facts_extracted = facts_extracted
        return assessment

    def _is_transient_error(self, error: str) -> bool:
        """Check if error is transient (shouldn't create censors).

        Transient patterns: timeout, rate limit, 429, 503, connection refused,
        network error, ECONNRESET, ETIMEDOUT.
        """
        error_lower = error.lower()
        return any(pattern in error_lower for pattern in _TRANSIENT_PATTERNS)

    def _error_to_censor_text(self, tool_result: ToolResult) -> str:
        """Convert a tool error to a censor trigger pattern.

        Format: "Avoid using {tool_name} when {simplified args} -- caused: {error[:100]}"
        """
        args_desc = ", ".join(f"{k}={v}" for k, v in list(tool_result.arguments.items())[:3])
        if args_desc:
            args_desc = f"with {args_desc}"
        error_snippet = (tool_result.error or "")[:100]
        return f"Avoid using {tool_result.tool_name} {args_desc} -- caused: {error_snippet}".strip()
