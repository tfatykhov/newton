"""Pydantic DTOs for the Cognitive Layer inputs and outputs.

These models define the data contract between the Cognitive Layer
and its consumers (the Runtime in 005).
"""

from __future__ import annotations

from enum import StrEnum

from pydantic import BaseModel, Field


class FrameType(StrEnum):
    TASK = "task"
    QUESTION = "question"
    DECISION = "decision"
    CREATIVE = "creative"
    CONVERSATION = "conversation"
    DEBUG = "debug"


class FrameSelection(BaseModel):
    """Result of frame selection."""

    frame_id: str
    frame_name: str
    confidence: float = Field(ge=0.0, le=1.0)
    match_method: str  # "pattern" or "default"
    description: str | None = None
    default_category: str | None = None
    default_stakes: str | None = None
    questions_to_ask: list[str] = Field(default_factory=list)


class ContextBudget(BaseModel):
    """Token allocation for context assembly."""

    total: int = 8000
    identity: int = 500
    censors: int = 300
    frame: int = 500
    working_memory: int = 700
    decisions: int = 2000
    facts: int = 1500
    procedures: int = 1500
    episodes: int = 1000
    conversation_window: int = 5  # D7: Number of turns for dedup window

    @classmethod
    def for_frame(cls, frame_id: str) -> ContextBudget:
        """Return frame-adaptive budget with per-frame conversation windows (D7)."""
        budgets = {
            "conversation": cls(total=3000, decisions=500, facts=500, procedures=0, episodes=0, conversation_window=3),
            "question": cls(total=6000, decisions=1000, facts=1500, procedures=500, episodes=500, conversation_window=5),
            "task": cls(total=8000, conversation_window=5),
            "decision": cls(total=12000, decisions=3000, facts=2000, procedures=2000, episodes=1000, conversation_window=8),
            "creative": cls(total=6000, censors=100, decisions=1000, facts=1500, procedures=500, episodes=500, conversation_window=4),
            "debug": cls(total=10000, decisions=1500, facts=1000, procedures=2500, episodes=1000, conversation_window=6),
        }
        return budgets.get(frame_id, cls())

    def apply_overrides(self, overrides: dict[str, int]) -> None:
        """Apply budget overrides with REPLACE semantics (F6).

        Each key in overrides maps to a field name on this model.
        Values replace (not add to) the current allocation.
        """
        for key, value in overrides.items():
            if hasattr(self, key):
                setattr(self, key, value)


class ContextSection(BaseModel):
    """A section of assembled context."""

    priority: int  # 1-8 (1=highest)
    label: str
    content: str
    token_estimate: int  # rough char/4 estimate


class BuildResult(BaseModel):
    """Output of ContextEngine.build() â€” system prompt + recalled IDs (F1)."""

    system_prompt: str
    sections: list[ContextSection] = Field(default_factory=list)
    recalled_ids: dict[str, list[str]] = Field(default_factory=dict)
    recalled_content_map: dict[str, str] = Field(default_factory=dict)


class TurnContext(BaseModel):
    """Output of pre_turn -- everything the agent needs."""

    system_prompt: str
    frame: FrameSelection
    decision_id: str | None = None  # Set if frame is 'decision' or 'task'
    active_censors: list[str] = Field(default_factory=list)
    context_token_estimate: int = 0
    recalled_decision_ids: list[str] = Field(default_factory=list)
    recalled_fact_ids: list[str] = Field(default_factory=list)
    recalled_procedure_ids: list[str] = Field(default_factory=list)
    recalled_episode_ids: list[str] = Field(default_factory=list)
    recalled_content_map: dict[str, str] = Field(default_factory=dict)


class ToolResult(BaseModel):
    """Representation of a tool call result for post_turn."""

    tool_name: str
    arguments: dict = Field(default_factory=dict)
    result: str | None = None
    error: str | None = None
    duration_ms: int | None = None


class TurnResult(BaseModel):
    """Input to post_turn -- what happened during the turn."""

    response_text: str
    tool_results: list[ToolResult] = Field(default_factory=list)
    error: str | None = None
    duration_ms: int | None = None


class Assessment(BaseModel):
    """Monitor engine output."""

    decision_id: str | None = None
    intended: str | None = None
    actual: str
    surprise_level: float = Field(ge=0.0, le=1.0, default=0.0)
    censor_candidates: list[str] = Field(default_factory=list)
    facts_extracted: int = 0
    episode_recorded: bool = False
