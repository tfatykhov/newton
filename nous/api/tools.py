"""Tool dispatcher and Nous memory tools for direct Anthropic API integration.

Provides:
- ToolDispatcher: registers tools, dispatches calls, filters by frame
- 4 tool closures that give Claude direct access to Nous memory organs:
  - record_decision: Write decisions to Brain
  - learn_fact: Store facts in Heart
  - recall_deep: Search all memory types (Heart + Brain)
  - create_censor: Add guardrails to Heart

Each tool returns MCP-compliant response format and handles errors gracefully.
"""

from __future__ import annotations

import logging
from collections.abc import Callable
from typing import Any
from uuid import UUID

from nous.brain.brain import Brain
from nous.brain.schemas import ReasonInput, RecordInput
from nous.heart.heart import Heart
from nous.heart.schemas import CensorInput, FactInput

logger = logging.getLogger(__name__)


# ---------------------------------------------------------------------------
# ToolDispatcher
# ---------------------------------------------------------------------------


class ToolDispatcher:
    """Registers tool handlers and dispatches tool calls from the API.

    Each handler is an async callable that accepts **kwargs and returns
    an MCP-format response: {"content": [{"type": "text", "text": "..."}]}.

    The dispatcher extracts plain text for the Anthropic API tool_result format.
    """

    def __init__(self) -> None:
        self._handlers: dict[str, Callable[..., Any]] = {}
        self._schemas: dict[str, dict[str, Any]] = {}  # P0-7 fix

    def register(self, name: str, handler: Callable[..., Any], schema: dict[str, Any]) -> None:
        """Register a tool handler with its JSON schema."""
        self._handlers[name] = handler
        self._schemas[name] = schema

    async def dispatch(self, name: str, args: dict[str, Any]) -> tuple[str, bool]:
        """Dispatch a tool call and return (result_text, is_error).

        P0-6 fix: Uses **kwargs unpacking for closures.
        P1-1 fix: Extracts text from MCP-format response.
        """
        handler = self._handlers.get(name)
        if not handler:
            return f"Unknown tool: {name}", True
        try:
            result = await handler(**args)  # P0-6: **kwargs unpacking
            # P1-1: Extract text from MCP-format response
            return result["content"][0]["text"], False
        except Exception as e:
            logger.exception("Tool dispatch error for %s", name)
            return f"Tool error: {e}", True

    def tool_definitions(self) -> list[dict[str, Any]]:
        """Return all tool definitions in Anthropic API format."""
        return [
            {
                "name": name,
                "description": schema.get("description", ""),
                "input_schema": schema,
            }
            for name, schema in self._schemas.items()
        ]

    def available_tools(self, frame_id: str) -> list[dict[str, Any]]:
        """Return tool definitions filtered by frame (D5).

        Uses FRAME_TOOLS map from runner module to determine which
        tools are available for a given frame. Wildcard "*" means all tools.
        """
        from nous.api.runner import FRAME_TOOLS

        allowed = FRAME_TOOLS.get(frame_id, [])

        # Wildcard means all tools
        if "*" in allowed:
            return self.tool_definitions()

        return [
            {
                "name": name,
                "description": schema.get("description", ""),
                "input_schema": schema,
            }
            for name, schema in self._schemas.items()
            if name in allowed
        ]


# ---------------------------------------------------------------------------
# Nous memory tool closures
# ---------------------------------------------------------------------------


def create_nous_tools(brain: Brain, heart: Heart) -> dict[str, Any]:
    """Create tool closures with Brain and Heart captured in closure context.

    Returns a dict of async callables suitable for ToolDispatcher registration.
    Each closure takes tool parameters, calls Brain/Heart methods, and returns
    MCP-compliant response: {"content": [{"type": "text", "text": "..."}]}.

    All tools are wrapped in try/except to return error messages as tool results.
    """

    async def record_decision(
        description: str,
        confidence: float,
        category: str,
        stakes: str,
        context: str | None = None,
        pattern: str | None = None,
        tags: list[str] | None = None,
        reasons: list[dict[str, str]] | None = None,
    ) -> dict[str, Any]:
        """Record a decision to the Brain.

        Args:
            description: What was decided
            confidence: 0.0-1.0 confidence level
            category: architecture, process, tooling, security, or integration
            stakes: low, medium, high, or critical
            context: Situation and constraints
            pattern: Abstract pattern this decision represents
            tags: Keywords for filtering
            reasons: List of {type, text} dicts (type: analysis, pattern, empirical, etc.)

        Returns:
            MCP-compliant response with decision ID or error message
        """
        try:
            # Validate and construct input
            reason_inputs = []
            if reasons:
                for r in reasons:
                    if not isinstance(r, dict) or "type" not in r or "text" not in r:
                        return {
                            "content": [
                                {
                                    "type": "text",
                                    "text": (
                                        f"Error: Invalid reason format. Expected dict with 'type' and 'text', got: {r}"
                                    ),
                                }
                            ]
                        }
                    reason_inputs.append(ReasonInput(type=r["type"], text=r["text"]))

            input_data = RecordInput(
                description=description,
                confidence=confidence,
                category=category,  # type: ignore
                stakes=stakes,  # type: ignore
                context=context,
                pattern=pattern,
                tags=tags or [],
                reasons=reason_inputs,
            )

            # Record to Brain
            result = await brain.record(input_data)

            return {
                "content": [
                    {
                        "type": "text",
                        "text": (
                            f"Decision recorded successfully.\n"
                            f"ID: {result.id}\n"
                            f"Quality score: {result.quality_score:.2f}\n"
                            f"Category: {result.category}\n"
                            f"Stakes: {result.stakes}"
                        ),
                    }
                ]
            }

        except Exception as e:
            logger.exception("record_decision tool failed")
            return {"content": [{"type": "text", "text": f"Error recording decision: {e}"}]}

    async def learn_fact(
        content: str,
        category: str | None = None,
        subject: str | None = None,
        confidence: float = 1.0,
        source: str | None = None,
        source_episode_id: str | None = None,
        source_decision_id: str | None = None,
        tags: list[str] | None = None,
    ) -> dict[str, Any]:
        """Store a fact in the Heart.

        Args:
            content: The fact content
            category: preference, technical, person, tool, concept, or rule
            subject: What/who the fact is about
            confidence: 0.0-1.0 confidence level
            source: Where this fact came from
            source_episode_id: Episode UUID if learned during episode
            source_decision_id: Decision UUID if learned during decision
            tags: Keywords for filtering

        Returns:
            MCP-compliant response with fact ID or error message
        """
        try:
            # Parse UUIDs if provided
            episode_uuid = UUID(source_episode_id) if source_episode_id else None
            decision_uuid = UUID(source_decision_id) if source_decision_id else None

            input_data = FactInput(
                content=content,
                category=category,
                subject=subject,
                confidence=confidence,
                source=source,
                source_episode_id=episode_uuid,
                source_decision_id=decision_uuid,
                tags=tags or [],
            )

            # Store to Heart
            result = await heart.learn(input_data)

            warning_msg = ""
            if result.contradiction_warning:
                warning_msg = (
                    f"\nPotential contradiction detected:\n"
                    f"Existing fact: {result.contradiction_warning.existing_content}\n"
                    f"Similarity: {result.contradiction_warning.similarity:.2f}"
                )

            return {
                "content": [
                    {
                        "type": "text",
                        "text": (
                            f"Fact learned successfully.\n"
                            f"ID: {result.id}\n"
                            f"Category: {result.category or 'none'}\n"
                            f"Subject: {result.subject or 'none'}"
                            f"{warning_msg}"
                        ),
                    }
                ]
            }

        except ValueError as e:
            # UUID parsing error or validation error
            return {"content": [{"type": "text", "text": f"Validation error: {e}"}]}
        except Exception as e:
            logger.exception("learn_fact tool failed")
            return {"content": [{"type": "text", "text": f"Error learning fact: {e}"}]}

    async def recall_deep(
        query: str,
        limit: int = 10,
        memory_types: list[str] | None = None,
    ) -> dict[str, Any]:
        """Search across all memory types in Heart and Brain.

        Args:
            query: Search query string
            limit: Maximum results to return
            memory_types: Types to search (episode, fact, procedure, censor, decision)
                         If None or contains "all", searches everything

        Returns:
            MCP-compliant response with ranked results or error message
        """
        try:
            # Determine which types to search
            search_types = memory_types or ["all"]
            search_all = "all" in search_types

            results_text = []

            # Search Heart memory types
            heart_types = []
            if search_all or any(t in search_types for t in ["episode", "fact", "procedure", "censor"]):
                # Determine specific Heart types
                if search_all:
                    heart_types = ["episode", "fact", "procedure", "censor"]
                else:
                    heart_types = [t for t in search_types if t in ["episode", "fact", "procedure", "censor"]]

                if heart_types:
                    heart_results = await heart.recall(query, limit=limit, types=heart_types)
                    if heart_results:
                        results_text.append("=== Heart Memory ===")
                        for i, result in enumerate(heart_results, 1):
                            results_text.append(
                                f"{i}. [{result.type}] {result.summary} (score: {result.score:.3f})"
                            )
                    else:
                        results_text.append("=== Heart Memory ===\nNo results found.")

            # Search Brain decisions
            if search_all or "decision" in search_types:
                decision_results = await brain.query(query, limit=limit)
                if decision_results:
                    results_text.append("\n=== Brain Decisions ===")
                    for i, dec in enumerate(decision_results, 1):
                        score_str = f" (score: {dec.score:.3f})" if dec.score else ""
                        results_text.append(
                            f"{i}. {dec.description} | {dec.category} | {dec.stakes} | "
                            f"confidence: {dec.confidence:.2f}{score_str}"
                        )
                else:
                    results_text.append("\n=== Brain Decisions ===\nNo results found.")

            if not results_text:
                results_text.append("No results found.")

            return {"content": [{"type": "text", "text": "\n".join(results_text)}]}

        except Exception as e:
            logger.exception("recall_deep tool failed")
            return {"content": [{"type": "text", "text": f"Error searching memory: {e}"}]}

    async def create_censor(
        trigger_pattern: str,
        reason: str,
        action: str = "warn",
        domain: str | None = None,
        learned_from_decision: str | None = None,
        learned_from_episode: str | None = None,
    ) -> dict[str, Any]:
        """Create a guardrail censor in the Heart.

        Args:
            trigger_pattern: Pattern to match (substring or regex)
            reason: Why this censor exists
            action: warn, block, or absolute
            domain: Domain this censor applies to (architecture, debugging, etc.)
            learned_from_decision: Decision UUID that triggered this censor
            learned_from_episode: Episode UUID that triggered this censor

        Returns:
            MCP-compliant response with censor ID or error message
        """
        try:
            # Parse UUIDs if provided
            decision_uuid = UUID(learned_from_decision) if learned_from_decision else None
            episode_uuid = UUID(learned_from_episode) if learned_from_episode else None

            input_data = CensorInput(
                trigger_pattern=trigger_pattern,
                reason=reason,
                action=action,  # type: ignore
                domain=domain,
                learned_from_decision=decision_uuid,
                learned_from_episode=episode_uuid,
            )

            # Create censor
            result = await heart.add_censor(input_data)

            return {
                "content": [
                    {
                        "type": "text",
                        "text": (
                            f"Censor created successfully.\n"
                            f"ID: {result.id}\n"
                            f"Action: {result.action}\n"
                            f"Domain: {result.domain or 'all'}\n"
                            f"Pattern: {result.trigger_pattern}"
                        ),
                    }
                ]
            }

        except ValueError as e:
            # UUID parsing error or validation error
            return {"content": [{"type": "text", "text": f"Validation error: {e}"}]}
        except Exception as e:
            logger.exception("create_censor tool failed")
            return {"content": [{"type": "text", "text": f"Error creating censor: {e}"}]}

    async def recall_recent(
        hours: int = 48,
        limit: int = 10,
    ) -> dict[str, Any]:
        """Recall recent episodes by time, not topic similarity.

        Use this when the user asks "what did we talk about", "what happened
        recently", or you need a comprehensive overview of recent activity.

        Args:
            hours: Look back this many hours (default 48)
            limit: Maximum episodes to return (default 10)

        Returns:
            MCP-compliant response with time-ordered episode list
        """
        try:
            episodes = await heart.list_episodes(limit=limit, hours=hours)

            if not episodes:
                return {"content": [{"type": "text", "text": f"No episodes found in the last {hours} hours."}]}

            lines = [f"Recent episodes (last {hours}h):"]
            for e in episodes:
                title = e.title or (e.summary[:60] if e.summary else "Untitled")
                time_str = e.started_at.strftime("%b %d %H:%M")
                lines.append(f"- [{time_str}] {title}")
                if e.summary and e.summary != e.title:
                    lines.append(f"  {e.summary[:150]}")

            return {"content": [{"type": "text", "text": "\n".join(lines)}]}

        except Exception as e:
            logger.exception("recall_recent tool failed")
            return {"content": [{"type": "text", "text": f"Error fetching recent episodes: {e}"}]}

    return {
        "record_decision": record_decision,
        "learn_fact": learn_fact,
        "recall_deep": recall_deep,
        "create_censor": create_censor,
        "recall_recent": recall_recent,
    }


# ---------------------------------------------------------------------------
# Tool schema definitions (Anthropic API format)
# ---------------------------------------------------------------------------

# JSON Schema definitions for each tool's input parameters.
# Field names match the closure parameter names exactly.

_RECORD_DECISION_SCHEMA: dict[str, Any] = {
    "type": "object",
    "description": "Record a decision to the Brain (decision intelligence organ)",
    "properties": {
        "description": {"type": "string", "description": "What was decided"},
        "confidence": {
            "type": "number",
            "description": "0.0-1.0 confidence level",
            "minimum": 0.0,
            "maximum": 1.0,
        },
        "category": {
            "type": "string",
            "description": "Decision category",
            "enum": ["architecture", "process", "tooling", "security", "integration"],
        },
        "stakes": {
            "type": "string",
            "description": "Stakes level",
            "enum": ["low", "medium", "high", "critical"],
        },
        "context": {"type": "string", "description": "Situation and constraints"},
        "pattern": {"type": "string", "description": "Abstract pattern this decision represents"},
        "tags": {
            "type": "array",
            "items": {"type": "string"},
            "description": "Keywords for filtering",
        },
        "reasons": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "type": {
                        "type": "string",
                        "enum": [
                            "analysis",
                            "pattern",
                            "empirical",
                            "authority",
                            "analogy",
                            "intuition",
                            "elimination",
                            "constraint",
                        ],
                    },
                    "text": {"type": "string"},
                },
                "required": ["type", "text"],
            },
            "description": "Supporting reasons",
        },
    },
    "required": ["description", "confidence", "category", "stakes"],
}

_LEARN_FACT_SCHEMA: dict[str, Any] = {
    "type": "object",
    "description": "Store a fact in the Heart (memory system)",
    "properties": {
        "content": {"type": "string", "description": "The fact content"},
        "category": {
            "type": "string",
            "description": "Fact category",
            "enum": ["preference", "technical", "person", "tool", "concept", "rule"],
        },
        "subject": {"type": "string", "description": "What/who the fact is about"},
        "confidence": {
            "type": "number",
            "description": "0.0-1.0 confidence level",
            "minimum": 0.0,
            "maximum": 1.0,
            "default": 1.0,
        },
        "source": {"type": "string", "description": "Where this fact came from"},
        "source_episode_id": {"type": "string", "description": "Episode UUID"},
        "source_decision_id": {"type": "string", "description": "Decision UUID"},
        "tags": {
            "type": "array",
            "items": {"type": "string"},
            "description": "Keywords for filtering",
        },
    },
    "required": ["content"],
}

_RECALL_DEEP_SCHEMA: dict[str, Any] = {
    "type": "object",
    "description": "Search across all memory types in Heart and Brain",
    "properties": {
        "query": {"type": "string", "description": "Search query string"},
        "limit": {
            "type": "integer",
            "description": "Maximum results to return",
            "default": 10,
            "minimum": 1,
            "maximum": 50,
        },
        "memory_types": {
            "type": "array",
            "items": {
                "type": "string",
                "enum": ["all", "episode", "fact", "procedure", "censor", "decision"],
            },
            "description": "Types to search. If omitted or contains 'all', searches everything.",
        },
    },
    "required": ["query"],
}

_CREATE_CENSOR_SCHEMA: dict[str, Any] = {
    "type": "object",
    "description": "Create a guardrail censor in the Heart",
    "properties": {
        "trigger_pattern": {
            "type": "string",
            "description": "Pattern to match (substring or regex)",
        },
        "reason": {"type": "string", "description": "Why this censor exists"},
        "action": {
            "type": "string",
            "description": "Censor action",
            "enum": ["warn", "block", "absolute"],
            "default": "warn",
        },
        "domain": {"type": "string", "description": "Domain this censor applies to"},
        "learned_from_decision": {"type": "string", "description": "Decision UUID"},
        "learned_from_episode": {"type": "string", "description": "Episode UUID"},
    },
    "required": ["trigger_pattern", "reason"],
}

_RECALL_RECENT_SCHEMA: dict[str, Any] = {
    "type": "object",
    "description": "Recall recent episodes by time (not topic similarity). Use when the user asks what you discussed recently or you need a temporal overview.",
    "properties": {
        "hours": {
            "type": "integer",
            "description": "Look back this many hours (default 48)",
            "default": 48,
        },
        "limit": {
            "type": "integer",
            "description": "Maximum episodes to return (default 10)",
            "default": 10,
        },
    },
    "required": [],
}


def register_nous_tools(dispatcher: ToolDispatcher, brain: Brain, heart: Heart) -> None:
    """Create Nous memory tools and register them with the dispatcher.

    This is the main wiring function called at startup to register
    all 4 memory tools with their schemas.
    """
    closures = create_nous_tools(brain, heart)

    dispatcher.register("record_decision", closures["record_decision"], _RECORD_DECISION_SCHEMA)
    dispatcher.register("learn_fact", closures["learn_fact"], _LEARN_FACT_SCHEMA)
    dispatcher.register("recall_deep", closures["recall_deep"], _RECALL_DEEP_SCHEMA)
    dispatcher.register("create_censor", closures["create_censor"], _CREATE_CENSOR_SCHEMA)
    dispatcher.register("recall_recent", closures["recall_recent"], _RECALL_RECENT_SCHEMA)


# ---------------------------------------------------------------------------
# Subtask & Schedule tool closures (011.1)
# ---------------------------------------------------------------------------


def create_subtask_tools(heart: Heart, settings: "Settings") -> dict[str, Any]:
    """Create subtask/schedule tool closures with Heart captured in closure context.

    Returns a dict of async callables suitable for ToolDispatcher registration.
    """
    from nous.config import Settings as _Settings  # noqa: F811 â€” deferred to avoid circular

    async def spawn_task(
        task: str,
        priority: str = "normal",
        timeout: int | None = None,
        notify: bool = True,
    ) -> dict[str, Any]:
        """Spawn a background subtask for the worker pool.

        Args:
            task: Natural-language instruction for the subtask
            priority: urgent, normal, or low
            timeout: Max seconds (clamped to settings.subtask_max_timeout)
            notify: Whether to notify on completion

        Returns:
            MCP-compliant response with subtask ID or error message
        """
        try:
            effective_timeout = min(
                timeout or settings.subtask_default_timeout,
                settings.subtask_max_timeout,
            )
            subtask = await heart.subtasks.create(
                task=task,
                priority=priority,
                timeout=effective_timeout,
                notify=notify,
            )
            return {
                "content": [
                    {
                        "type": "text",
                        "text": (
                            f"Subtask spawned.\n"
                            f"ID: {subtask.id}\n"
                            f"Priority: {priority}\n"
                            f"Timeout: {effective_timeout}s"
                        ),
                    }
                ]
            }
        except ValueError as e:
            return {"content": [{"type": "text", "text": f"Cannot spawn subtask: {e}"}]}
        except Exception as e:
            logger.exception("spawn_task tool failed")
            return {"content": [{"type": "text", "text": f"Error spawning subtask: {e}"}]}

    async def schedule_task(
        task: str,
        when: str | None = None,
        every: str | None = None,
        notify: bool = True,
    ) -> dict[str, Any]:
        """Schedule a task for later or recurring execution.

        Exactly one of ``when`` or ``every`` must be provided.

        Args:
            task: Natural-language instruction
            when: One-shot time (e.g. "in 2 hours", ISO 8601)
            every: Recurring pattern (e.g. "daily at 8am", "30 minutes")
            notify: Whether to notify on each fire

        Returns:
            MCP-compliant response with schedule ID and next fire time
        """
        try:
            if bool(when) == bool(every):
                return {
                    "content": [
                        {
                            "type": "text",
                            "text": "Exactly one of 'when' or 'every' must be provided.",
                        }
                    ]
                }

            from nous.handlers.time_parser import parse_every, parse_when

            if when:
                fire_at = parse_when(when)
                schedule = await heart.schedules.create(
                    task=task,
                    schedule_type="once",
                    fire_at=fire_at,
                    notify=notify,
                    timeout=settings.subtask_default_timeout,
                )
            else:
                interval_seconds, cron_expr = parse_every(every)  # type: ignore[arg-type]
                schedule = await heart.schedules.create(
                    task=task,
                    schedule_type="recurring",
                    interval_seconds=interval_seconds,
                    cron_expr=cron_expr,
                    notify=notify,
                    timeout=settings.subtask_default_timeout,
                )

            next_fire = (
                schedule.next_fire_at.isoformat() if schedule.next_fire_at else "N/A"
            )
            return {
                "content": [
                    {
                        "type": "text",
                        "text": (
                            f"Schedule created.\n"
                            f"ID: {schedule.id}\n"
                            f"Type: {schedule.schedule_type}\n"
                            f"Next fire: {next_fire}"
                        ),
                    }
                ]
            }
        except ValueError as e:
            return {"content": [{"type": "text", "text": f"Schedule error: {e}"}]}
        except Exception as e:
            logger.exception("schedule_task tool failed")
            return {"content": [{"type": "text", "text": f"Error scheduling task: {e}"}]}

    async def list_tasks(
        status: str | None = None,
    ) -> dict[str, Any]:
        """List subtasks and schedules.

        Args:
            status: Filter subtasks by status (pending, running, completed, failed, cancelled)

        Returns:
            MCP-compliant response with formatted task list
        """
        try:
            subtasks = await heart.subtasks.list(status=status, limit=20)
            schedules = await heart.schedules.list(active_only=True, limit=20)

            lines: list[str] = []

            if subtasks:
                lines.append("=== Subtasks ===")
                for st in subtasks:
                    lines.append(
                        f"- [{st.status}] {st.id} | {st.task[:80]}"
                    )
            else:
                lines.append("=== Subtasks ===\nNo subtasks found.")

            if schedules:
                lines.append("\n=== Schedules ===")
                for sc in schedules:
                    next_fire = (
                        sc.next_fire_at.strftime("%Y-%m-%d %H:%M UTC")
                        if sc.next_fire_at
                        else "N/A"
                    )
                    lines.append(
                        f"- [{sc.schedule_type}] {sc.id} | {sc.task[:80]} (next: {next_fire})"
                    )
            else:
                lines.append("\n=== Schedules ===\nNo active schedules.")

            return {"content": [{"type": "text", "text": "\n".join(lines)}]}
        except Exception as e:
            logger.exception("list_tasks tool failed")
            return {"content": [{"type": "text", "text": f"Error listing tasks: {e}"}]}

    async def cancel_task(
        task_id: str,
    ) -> dict[str, Any]:
        """Cancel a subtask or deactivate a schedule by ID.

        Args:
            task_id: UUID of the subtask or schedule to cancel

        Returns:
            MCP-compliant response confirming cancellation or error
        """
        try:
            from uuid import UUID as _UUID

            uid = _UUID(task_id)

            # Try subtask cancel first
            cancelled = await heart.subtasks.cancel(uid)
            if cancelled:
                return {
                    "content": [
                        {"type": "text", "text": f"Subtask {task_id} cancelled."}
                    ]
                }

            # Try schedule deactivation
            schedule = await heart.schedules.get(uid)
            if schedule:
                await heart.schedules.deactivate(uid)
                return {
                    "content": [
                        {"type": "text", "text": f"Schedule {task_id} deactivated."}
                    ]
                }

            return {
                "content": [
                    {"type": "text", "text": f"No pending subtask or active schedule found for {task_id}."}
                ]
            }
        except ValueError:
            return {"content": [{"type": "text", "text": f"Invalid task ID: {task_id}"}]}
        except Exception as e:
            logger.exception("cancel_task tool failed")
            return {"content": [{"type": "text", "text": f"Error cancelling task: {e}"}]}

    return {
        "spawn_task": spawn_task,
        "schedule_task": schedule_task,
        "list_tasks": list_tasks,
        "cancel_task": cancel_task,
    }


# ---------------------------------------------------------------------------
# Subtask & Schedule tool schemas (Anthropic API format)
# ---------------------------------------------------------------------------

_SPAWN_TASK_SCHEMA: dict[str, Any] = {
    "type": "object",
    "description": "Spawn a background subtask for the worker pool to execute autonomously",
    "properties": {
        "task": {
            "type": "string",
            "description": "Natural-language instruction for the subtask",
        },
        "priority": {
            "type": "string",
            "description": "Task priority",
            "enum": ["urgent", "normal", "low"],
            "default": "normal",
        },
        "timeout": {
            "type": "integer",
            "description": "Max execution seconds (clamped to server max)",
            "minimum": 10,
        },
        "notify": {
            "type": "boolean",
            "description": "Notify on completion",
            "default": True,
        },
    },
    "required": ["task"],
}

_SCHEDULE_TASK_SCHEMA: dict[str, Any] = {
    "type": "object",
    "description": "Schedule a task for later or recurring execution. Provide exactly one of 'when' or 'every'.",
    "properties": {
        "task": {
            "type": "string",
            "description": "Natural-language instruction for the task",
        },
        "when": {
            "type": "string",
            "description": "One-shot time: 'in 2 hours', ISO 8601, or natural language",
        },
        "every": {
            "type": "string",
            "description": "Recurring pattern: 'daily at 8am', '30 minutes', 'every monday at 10am'",
        },
        "notify": {
            "type": "boolean",
            "description": "Notify on each fire",
            "default": True,
        },
    },
    "required": ["task"],
}

_LIST_TASKS_SCHEMA: dict[str, Any] = {
    "type": "object",
    "description": "List current subtasks and active schedules",
    "properties": {
        "status": {
            "type": "string",
            "description": "Filter subtasks by status",
            "enum": ["pending", "running", "completed", "failed", "cancelled"],
        },
    },
    "required": [],
}

_CANCEL_TASK_SCHEMA: dict[str, Any] = {
    "type": "object",
    "description": "Cancel a subtask or deactivate a schedule by ID",
    "properties": {
        "task_id": {
            "type": "string",
            "description": "UUID of the subtask or schedule to cancel",
        },
    },
    "required": ["task_id"],
}


def register_subtask_tools(dispatcher: ToolDispatcher, heart: Heart, settings: "Settings") -> None:
    """Create subtask/schedule tools and register them with the dispatcher.

    Called at startup when subtask_enabled is True.
    """
    closures = create_subtask_tools(heart, settings)

    dispatcher.register("spawn_task", closures["spawn_task"], _SPAWN_TASK_SCHEMA)
    dispatcher.register("schedule_task", closures["schedule_task"], _SCHEDULE_TASK_SCHEMA)
    dispatcher.register("list_tasks", closures["list_tasks"], _LIST_TASKS_SCHEMA)
    dispatcher.register("cancel_task", closures["cancel_task"], _CANCEL_TASK_SCHEMA)
